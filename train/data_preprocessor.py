import json
import numpy as np
import os
import pandas as pd
from typing import Dict, List, Tuple, Any, Optional
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split
import pickle
import warnings
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns


class HandGesturePreprocessor:
    """æ‰‹è¯­æ•°æ®é¢„å¤„ç†å™¨ - ç”¨äºå¤„ç†åŸå§‹Leap Motionæ•°æ®"""

    def __init__(self, data_dir: str = "data"):
        self.data_dir = data_dir
        self.raw_data_dir = os.path.join(data_dir, "raw")
        self.annotations_dir = os.path.join(data_dir, "annotations")
        self.processed_data_dir = os.path.join(data_dir, "processed")
        self.models_dir = os.path.join(data_dir, "models")

        # åˆ›å»ºå¤„ç†åæ•°æ®ç›®å½•
        os.makedirs(self.processed_data_dir, exist_ok=True)
        os.makedirs(self.models_dir, exist_ok=True)

        # ç‰¹å¾é…ç½®
        self.feature_config = {
            "sequence_length": 30,  # å›ºå®šåºåˆ—é•¿åº¦
            "palm_features": True,
            "arm_features": True,
            "digit_features": True,
            "bone_features": True,
            "velocity_features": True,
            "angle_features": True,
            "distance_features": True
        }

        # æ•°æ®ç¼©æ”¾å™¨
        self.scaler = StandardScaler()
        self.is_scaler_fitted = False

        # æ ‡ç­¾ç¼–ç 
        self.label_encoder = {}
        self.label_decoder = {}

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {}

    def load_raw_data(self) -> List[Dict]:
        """åŠ è½½æ‰€æœ‰åŸå§‹æ•°æ®æ–‡ä»¶"""
        raw_data = []

        if not os.path.exists(self.raw_data_dir):
            print(f"åŸå§‹æ•°æ®ç›®å½•ä¸å­˜åœ¨: {self.raw_data_dir}")
            return raw_data

        files = [f for f in os.listdir(self.raw_data_dir) if f.endswith('.json')]
        print(f"æ‰¾åˆ° {len(files)} ä¸ªåŸå§‹æ•°æ®æ–‡ä»¶")

        for filename in files:
            filepath = os.path.join(self.raw_data_dir, filename)
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    data['filename'] = filename
                    raw_data.append(data)
            except Exception as e:
                print(f"åŠ è½½æ–‡ä»¶å¤±è´¥ {filename}: {e}")

        print(f"æˆåŠŸåŠ è½½ {len(raw_data)} ä¸ªæ•°æ®æ–‡ä»¶")
        return raw_data

    def extract_palm_features(self, palm_data: Dict) -> np.ndarray:
        """æå–æ‰‹æŒç‰¹å¾"""
        features = []

        if self.feature_config["palm_features"]:
            # ä½ç½®ç‰¹å¾
            features.extend(palm_data.get("position", [0, 0, 0]))
            # æ–¹å‘ç‰¹å¾
            features.extend(palm_data.get("direction", [0, 0, 0]))
            # æ³•å‘é‡ç‰¹å¾
            features.extend(palm_data.get("normal", [0, 0, 0]))
            # é€Ÿåº¦ç‰¹å¾
            if self.feature_config["velocity_features"]:
                features.extend(palm_data.get("velocity", [0, 0, 0]))
            # å®½åº¦ç‰¹å¾
            features.append(palm_data.get("width", 0))

        return np.array(features)

    def extract_arm_features(self, arm_data: Dict) -> np.ndarray:
        """æå–æ‰‹è‡‚ç‰¹å¾"""
        features = []

        if self.feature_config["arm_features"]:
            # å…³èŠ‚ä½ç½®
            features.extend(arm_data.get("prev_joint", [0, 0, 0]))
            features.extend(arm_data.get("next_joint", [0, 0, 0]))
            # æ–¹å‘
            features.extend(arm_data.get("direction", [0, 0, 0]))
            # é•¿åº¦å’Œå®½åº¦
            features.append(arm_data.get("length", 0))
            features.append(arm_data.get("width", 0))

        return np.array(features)

    def extract_digit_features(self, digit_data: Dict) -> np.ndarray:
        """æå–æ‰‹æŒ‡ç‰¹å¾"""
        features = []

        if self.feature_config["digit_features"]:
            # æ˜¯å¦ä¼¸å±•
            features.append(float(digit_data.get("is_extended", False)))

            # éª¨éª¼ç‰¹å¾
            if self.feature_config["bone_features"]:
                bones = digit_data.get("bones", [])
                for bone in bones:
                    # å…³èŠ‚ä½ç½®
                    features.extend(bone.get("prev_joint", [0, 0, 0]))
                    features.extend(bone.get("next_joint", [0, 0, 0]))
                    # æ–¹å‘
                    features.extend(bone.get("direction", [0, 0, 0]))
                    # é•¿åº¦å’Œå®½åº¦
                    features.append(bone.get("length", 0))
                    features.append(bone.get("width", 0))

        return np.array(features)

    def calculate_angles(self, hand_data: Dict) -> np.ndarray:
        """è®¡ç®—æ‰‹æŒ‡é—´è§’åº¦ç­‰å‡ ä½•ç‰¹å¾"""
        angles = []

        if not self.feature_config["angle_features"]:
            return np.array(angles)

        digits = hand_data.get("digits", [])

        # è®¡ç®—ç›¸é‚»æ‰‹æŒ‡é—´çš„è§’åº¦
        for i in range(len(digits) - 1):
            digit1 = digits[i]
            digit2 = digits[i + 1]

            # è·å–æ‰‹æŒ‡åŸºéƒ¨æ–¹å‘å‘é‡
            if digit1.get("bones") and digit2.get("bones"):
                bone1 = digit1["bones"][0]  # æŒéª¨
                bone2 = digit2["bones"][0]

                dir1 = np.array(bone1.get("direction", [0, 0, 0]))
                dir2 = np.array(bone2.get("direction", [0, 0, 0]))

                # è®¡ç®—è§’åº¦
                if np.linalg.norm(dir1) > 0 and np.linalg.norm(dir2) > 0:
                    cos_angle = np.dot(dir1, dir2) / (np.linalg.norm(dir1) * np.linalg.norm(dir2))
                    cos_angle = np.clip(cos_angle, -1, 1)
                    angle = np.arccos(cos_angle)
                    angles.append(angle)
                else:
                    angles.append(0)

        return np.array(angles)

    def calculate_distances(self, hand_data: Dict) -> np.ndarray:
        """è®¡ç®—å…³é”®ç‚¹é—´è·ç¦»"""
        distances = []

        if not self.feature_config["distance_features"]:
            return np.array(distances)

        palm_pos = np.array(hand_data.get("palm", {}).get("position", [0, 0, 0]))
        digits = hand_data.get("digits", [])

        # è®¡ç®—æ‰‹æŒ‡å°–åˆ°æ‰‹æŒçš„è·ç¦»
        for digit in digits:
            bones = digit.get("bones", [])
            if bones:
                # æ‰‹æŒ‡å°–ä½ç½®ï¼ˆæœ€åä¸€ä¸ªéª¨éª¼çš„æœ«ç«¯ï¼‰
                fingertip_pos = np.array(bones[-1].get("next_joint", [0, 0, 0]))
                distance = np.linalg.norm(fingertip_pos - palm_pos)
                distances.append(distance)

        # è®¡ç®—æ‰‹æŒ‡é—´è·ç¦»
        fingertips = []
        for digit in digits:
            bones = digit.get("bones", [])
            if bones:
                fingertip_pos = np.array(bones[-1].get("next_joint", [0, 0, 0]))
                fingertips.append(fingertip_pos)

        for i in range(len(fingertips)):
            for j in range(i + 1, len(fingertips)):
                distance = np.linalg.norm(fingertips[i] - fingertips[j])
                distances.append(distance)

        return np.array(distances)

    def extract_hand_features(self, hand_data: Dict) -> np.ndarray:
        """æå–å•åªæ‰‹çš„æ‰€æœ‰ç‰¹å¾"""
        features = []

        # åŸºæœ¬ä¿¡æ¯
        hand_type = 1.0 if hand_data.get("hand_type") == "right" else 0.0
        features.append(hand_type)
        features.append(hand_data.get("confidence", 0))
        features.append(hand_data.get("grab_strength", 0))
        features.append(hand_data.get("grab_angle", 0))
        features.append(hand_data.get("pinch_distance", 0))
        features.append(hand_data.get("pinch_strength", 0))

        # æ‰‹æŒç‰¹å¾
        palm_features = self.extract_palm_features(hand_data.get("palm", {}))
        features.extend(palm_features)

        # æ‰‹è‡‚ç‰¹å¾
        arm_features = self.extract_arm_features(hand_data.get("arm", {}))
        features.extend(arm_features)

        # æ‰‹æŒ‡ç‰¹å¾
        digits = hand_data.get("digits", [])
        for digit in digits:
            digit_features = self.extract_digit_features(digit)
            features.extend(digit_features)

        # å‡ ä½•ç‰¹å¾
        angle_features = self.calculate_angles(hand_data)
        features.extend(angle_features)

        distance_features = self.calculate_distances(hand_data)
        features.extend(distance_features)

        return np.array(features)

    def extract_frame_features(self, frame_data: Dict) -> np.ndarray:
        """æå–å•å¸§ç‰¹å¾"""
        features = []

        hands = frame_data.get("hands", [])

        # å¤„ç†åŒæ‰‹æƒ…å†µ
        left_hand_features = np.zeros(200)  # å‡è®¾å•æ‰‹ç‰¹å¾ç»´åº¦ä¸º200
        right_hand_features = np.zeros(200)

        for hand in hands:
            hand_features = self.extract_hand_features(hand)

            # ç¡®ä¿ç‰¹å¾ç»´åº¦ä¸€è‡´
            if len(hand_features) > 200:
                hand_features = hand_features[:200]
            elif len(hand_features) < 200:
                hand_features = np.pad(hand_features, (0, 200 - len(hand_features)))

            if hand.get("hand_type") == "left":
                left_hand_features = hand_features
            else:
                right_hand_features = hand_features

        # åˆå¹¶åŒæ‰‹ç‰¹å¾
        features.extend(left_hand_features)
        features.extend(right_hand_features)

        # æ·»åŠ æ‰‹çš„æ•°é‡ä¿¡æ¯
        features.append(len(hands))

        return np.array(features)

    def normalize_sequence_length(self, sequence: np.ndarray, target_length: int) -> np.ndarray:
        """æ ‡å‡†åŒ–åºåˆ—é•¿åº¦"""
        current_length = len(sequence)

        if current_length == target_length:
            return sequence
        elif current_length < target_length:
            # å¡«å……ï¼šé‡å¤æœ€åä¸€å¸§
            padding = np.repeat(sequence[-1:], target_length - current_length, axis=0)
            return np.vstack([sequence, padding])
        else:
            # æˆªæ–­ï¼šç­‰é—´éš”é‡‡æ ·
            indices = np.linspace(0, current_length - 1, target_length, dtype=int)
            return sequence[indices]

    def process_gesture_data(self, gesture_data: Dict) -> Tuple[np.ndarray, str, str, str]:
        """å¤„ç†å•ä¸ªæ‰‹åŠ¿æ•°æ®"""
        frames = gesture_data.get("frames", [])
        if not frames:
            return None, None, None, None

        # æå–æ¯å¸§ç‰¹å¾
        sequence_features = []
        for frame in frames:
            frame_features = self.extract_frame_features(frame)
            sequence_features.append(frame_features)

        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        sequence_features = np.array(sequence_features)

        # æ ‡å‡†åŒ–åºåˆ—é•¿åº¦
        sequence_features = self.normalize_sequence_length(
            sequence_features, self.feature_config["sequence_length"]
        )

        # è·å–æ ‡ç­¾
        gesture_label = gesture_data.get("gesture_label", "")
        chinese_meaning = gesture_data.get("chinese_meaning", "")
        english_meaning = gesture_data.get("english_meaning", "")

        return sequence_features, gesture_label, chinese_meaning, english_meaning

    def build_label_encoders(self, raw_data: List[Dict]):
        """æ„å»ºæ ‡ç­¾ç¼–ç å™¨"""
        gesture_labels = set()
        chinese_meanings = set()
        english_meanings = set()

        for data in raw_data:
            gesture_labels.add(data.get("gesture_label", ""))
            chinese_meanings.add(data.get("chinese_meaning", ""))
            english_meanings.add(data.get("english_meaning", ""))

        # åˆ›å»ºç¼–ç æ˜ å°„
        self.label_encoder = {
            "gesture": {label: idx for idx, label in enumerate(sorted(gesture_labels))},
            "chinese": {label: idx for idx, label in enumerate(sorted(chinese_meanings))},
            "english": {label: idx for idx, label in enumerate(sorted(english_meanings))}
        }

        # åˆ›å»ºè§£ç æ˜ å°„
        self.label_decoder = {
            "gesture": {idx: label for label, idx in self.label_encoder["gesture"].items()},
            "chinese": {idx: label for label, idx in self.label_encoder["chinese"].items()},
            "english": {idx: label for label, idx in self.label_encoder["english"].items()}
        }

        print(f"æ ‡ç­¾ç¼–ç å™¨æ„å»ºå®Œæˆ:")
        print(f"  æ‰‹åŠ¿æ ‡ç­¾: {len(self.label_encoder['gesture'])}")
        print(f"  ä¸­æ–‡å«ä¹‰: {len(self.label_encoder['chinese'])}")
        print(f"  è‹±æ–‡å«ä¹‰: {len(self.label_encoder['english'])}")

    def process_all_data(self) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
        """å¤„ç†æ‰€æœ‰æ•°æ®"""
        print("å¼€å§‹å¤„ç†æ‰€æœ‰æ•°æ®...")

        # åŠ è½½åŸå§‹æ•°æ®
        raw_data = self.load_raw_data()
        if not raw_data:
            raise ValueError("æ²¡æœ‰æ‰¾åˆ°åŸå§‹æ•°æ®æ–‡ä»¶")

        print(f"æ‰¾åˆ° {len(raw_data)} ä¸ªåŸå§‹æ•°æ®æ–‡ä»¶")

        # æ„å»ºæ ‡ç­¾ç¼–ç å™¨
        self.build_label_encoders(raw_data)

        # å¤„ç†æ¯ä¸ªæ‰‹åŠ¿æ•°æ®
        all_features = []
        all_gesture_labels = []
        all_chinese_labels = []
        all_english_labels = []

        valid_count = 0
        invalid_count = 0

        for i, data in enumerate(raw_data):
            try:
                features, gesture_label, chinese_meaning, english_meaning = self.process_gesture_data(data)

                if features is not None and features.size > 0:
                    all_features.append(features)
                    all_gesture_labels.append(self.label_encoder["gesture"][gesture_label])
                    all_chinese_labels.append(self.label_encoder["chinese"][chinese_meaning])
                    all_english_labels.append(self.label_encoder["english"][english_meaning])
                    valid_count += 1
                    print(f"å¤„ç†æ–‡ä»¶ {i + 1}/{len(raw_data)}: æˆåŠŸ - {chinese_meaning}({english_meaning})")
                else:
                    invalid_count += 1
                    print(f"å¤„ç†æ–‡ä»¶ {i + 1}/{len(raw_data)}: å¤±è´¥ - æ— æ•ˆæ•°æ®")
            except Exception as e:
                invalid_count += 1
                print(f"å¤„ç†æ–‡ä»¶ {i + 1}/{len(raw_data)}: å¤±è´¥ - {e}")

        print(f"æ•°æ®å¤„ç†å®Œæˆ: æœ‰æ•ˆæ•°æ® {valid_count}, æ— æ•ˆæ•°æ® {invalid_count}")

        if valid_count == 0:
            raise ValueError("æ²¡æœ‰æœ‰æ•ˆçš„æ•°æ®å¯ç”¨äºè®­ç»ƒ")

        # æ£€æŸ¥æ•°æ®æ”¶é›†å»ºè®®
        if valid_count < 10:
            print("\nâš ï¸  æ•°æ®ä¸è¶³è­¦å‘Š:")
            print(f"   å½“å‰åªæœ‰ {valid_count} ä¸ªæœ‰æ•ˆæ ·æœ¬")
            print("   å»ºè®®:")
            print("   1. æ¯ä¸ªæ‰‹åŠ¿è‡³å°‘æ”¶é›† 10-20 ä¸ªæ ·æœ¬")
            print("   2. åœ¨ä¸åŒå…‰ç…§æ¡ä»¶ä¸‹æ”¶é›†æ•°æ®")
            print("   3. ç”¨ä¸åŒçš„æ‰‹åŠ¿é€Ÿåº¦æ”¶é›†æ•°æ®")
            print("   4. ç¡®ä¿æ‰‹åŠ¿åŠ¨ä½œå®Œæ•´å’Œæ¸…æ™°")
            print()

        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        X = np.array(all_features)
        y_gesture = np.array(all_gesture_labels)
        y_chinese = np.array(all_chinese_labels)
        y_english = np.array(all_english_labels)

        print(f"æ•°æ®å½¢çŠ¶æ£€æŸ¥:")
        print(f"  ç‰¹å¾çŸ©é˜µ: {X.shape}")
        print(f"  æ‰‹åŠ¿æ ‡ç­¾: {y_gesture.shape}")
        print(f"  ä¸­æ–‡æ ‡ç­¾: {y_chinese.shape}")
        print(f"  è‹±æ–‡æ ‡ç­¾: {y_english.shape}")

        # æ•°æ®æ ‡å‡†åŒ–
        if X.size > 0:
            original_shape = X.shape
            X_reshaped = X.reshape(-1, X.shape[-1])

            if not self.is_scaler_fitted:
                print("æ‹Ÿåˆæ•°æ®ç¼©æ”¾å™¨...")
                X_scaled = self.scaler.fit_transform(X_reshaped)
                self.is_scaler_fitted = True
            else:
                X_scaled = self.scaler.transform(X_reshaped)

            X = X_scaled.reshape(original_shape)
            print("æ•°æ®æ ‡å‡†åŒ–å®Œæˆ")

        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        self.generate_statistics(X, y_gesture, y_chinese, y_english)

        return X, y_gesture, y_chinese, y_english

    def generate_statistics(self, X: np.ndarray, y_gesture: np.ndarray,
                            y_chinese: np.ndarray, y_english: np.ndarray):
        """ç”Ÿæˆæ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
        self.stats = {
            "total_samples": len(X),
            "sequence_length": X.shape[1],
            "feature_dimension": X.shape[2],
            "num_gesture_classes": len(self.label_encoder["gesture"]),
            "num_chinese_classes": len(self.label_encoder["chinese"]),
            "num_english_classes": len(self.label_encoder["english"]),
            "feature_mean": np.mean(X),
            "feature_std": np.std(X),
            "feature_min": np.min(X),
            "feature_max": np.max(X),
            "class_distribution": {
                "gesture": {self.label_decoder["gesture"][i]: np.sum(y_gesture == i)
                            for i in range(len(self.label_decoder["gesture"]))},
                "chinese": {self.label_decoder["chinese"][i]: np.sum(y_chinese == i)
                            for i in range(len(self.label_decoder["chinese"]))},
                "english": {self.label_decoder["english"][i]: np.sum(y_english == i)
                            for i in range(len(self.label_decoder["english"]))}
            }
        }

        print("\næ•°æ®ç»Ÿè®¡ä¿¡æ¯:")
        print(f"æ€»æ ·æœ¬æ•°: {self.stats['total_samples']}")
        print(f"åºåˆ—é•¿åº¦: {self.stats['sequence_length']}")
        print(f"ç‰¹å¾ç»´åº¦: {self.stats['feature_dimension']}")
        print(f"æ‰‹åŠ¿ç±»åˆ«æ•°: {self.stats['num_gesture_classes']}")
        print(f"ä¸­æ–‡ç±»åˆ«æ•°: {self.stats['num_chinese_classes']}")
        print(f"è‹±æ–‡ç±»åˆ«æ•°: {self.stats['num_english_classes']}")

    def split_data(self, X: np.ndarray, y_gesture: np.ndarray, y_chinese: np.ndarray,
                   y_english: np.ndarray, test_size: float = 0.2, val_size: float = 0.1):
        """åˆ†å‰²æ•°æ®é›†"""
        total_samples = len(X)

        # æ£€æŸ¥æ ·æœ¬æ•°é‡
        if total_samples < 3:
            print(f"è­¦å‘Š: æ ·æœ¬æ•°é‡å¤ªå°‘ ({total_samples})ï¼Œæ— æ³•è¿›è¡Œæ•°æ®åˆ†å‰²")
            print("å°†æ‰€æœ‰æ•°æ®ç”¨ä½œè®­ç»ƒé›†")
            return {
                "X_train": X, "y_gesture_train": y_gesture,
                "y_chinese_train": y_chinese, "y_english_train": y_english,
                "X_test": X, "y_gesture_test": y_gesture,
                "y_chinese_test": y_chinese, "y_english_test": y_english
            }

        # è°ƒæ•´åˆ†å‰²æ¯”ä¾‹ä»¥é€‚åº”å°æ ·æœ¬
        min_test_samples = 1
        min_val_samples = 1 if val_size > 0 else 0

        # ç¡®ä¿æµ‹è¯•é›†è‡³å°‘æœ‰1ä¸ªæ ·æœ¬
        effective_test_size = max(min_test_samples / total_samples, test_size)
        effective_test_size = min(effective_test_size, 0.5)  # æœ€å¤š50%ä½œä¸ºæµ‹è¯•é›†

        # ç¡®ä¿éªŒè¯é›†è‡³å°‘æœ‰1ä¸ªæ ·æœ¬ï¼ˆå¦‚æœéœ€è¦éªŒè¯é›†ï¼‰
        if val_size > 0:
            effective_val_size = max(min_val_samples / (total_samples * (1 - effective_test_size)), val_size)
            effective_val_size = min(effective_val_size, 0.3)  # æœ€å¤š30%ä½œä¸ºéªŒè¯é›†
        else:
            effective_val_size = 0

        print(f"æ•°æ®åˆ†å‰²ä¿¡æ¯:")
        print(f"  æ€»æ ·æœ¬æ•°: {total_samples}")
        print(f"  æµ‹è¯•é›†æ¯”ä¾‹: {effective_test_size:.2f}")
        print(f"  éªŒè¯é›†æ¯”ä¾‹: {effective_val_size:.2f}")

        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ¯ä¸ªç±»åˆ«çš„æ ·æœ¬è¿›è¡Œåˆ†å±‚æŠ½æ ·
            unique_classes, class_counts = np.unique(y_gesture, return_counts=True)
            min_class_count = np.min(class_counts)

            if min_class_count < 2:
                print("è­¦å‘Š: æŸäº›ç±»åˆ«æ ·æœ¬æ•°é‡å¤ªå°‘ï¼Œä½¿ç”¨éšæœºåˆ†å‰²è€Œéåˆ†å±‚æŠ½æ ·")
                stratify = None
            else:
                stratify = y_gesture

            # é¦–å…ˆåˆ†ç¦»è®­ç»ƒé›†å’Œæµ‹è¯•é›†
            X_train, X_test, y_gesture_train, y_gesture_test, y_chinese_train, y_chinese_test, y_english_train, y_english_test = train_test_split(
                X, y_gesture, y_chinese, y_english,
                test_size=effective_test_size,
                random_state=42,
                stratify=stratify
            )

            # ä»è®­ç»ƒé›†ä¸­åˆ†ç¦»éªŒè¯é›†
            if effective_val_size > 0 and len(X_train) >= 2:
                # é‡æ–°è®¡ç®—éªŒè¯é›†åœ¨å‰©ä½™è®­ç»ƒæ•°æ®ä¸­çš„æ¯”ä¾‹
                val_size_adjusted = effective_val_size / (1 - effective_test_size)

                # æ£€æŸ¥æ˜¯å¦èƒ½è¿›è¡Œåˆ†å±‚æŠ½æ ·
                unique_train_classes, train_class_counts = np.unique(y_gesture_train, return_counts=True)
                min_train_class_count = np.min(train_class_counts)

                if min_train_class_count < 2:
                    train_stratify = None
                else:
                    train_stratify = y_gesture_train

                try:
                    X_train, X_val, y_gesture_train, y_gesture_val, y_chinese_train, y_chinese_val, y_english_train, y_english_val = train_test_split(
                        X_train, y_gesture_train, y_chinese_train, y_english_train,
                        test_size=val_size_adjusted,
                        random_state=42,
                        stratify=train_stratify
                    )

                    result = {
                        "X_train": X_train, "y_gesture_train": y_gesture_train,
                        "y_chinese_train": y_chinese_train, "y_english_train": y_english_train,
                        "X_val": X_val, "y_gesture_val": y_gesture_val,
                        "y_chinese_val": y_chinese_val, "y_english_val": y_english_val,
                        "X_test": X_test, "y_gesture_test": y_gesture_test,
                        "y_chinese_test": y_chinese_test, "y_english_test": y_english_test
                    }

                    print(f"  è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬")
                    print(f"  éªŒè¯é›†: {len(X_val)} æ ·æœ¬")
                    print(f"  æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬")

                    return result

                except ValueError as e:
                    print(f"éªŒè¯é›†åˆ†å‰²å¤±è´¥ï¼Œè·³è¿‡éªŒè¯é›†: {e}")

            # æ²¡æœ‰éªŒè¯é›†çš„æƒ…å†µ
            result = {
                "X_train": X_train, "y_gesture_train": y_gesture_train,
                "y_chinese_train": y_chinese_train, "y_english_train": y_english_train,
                "X_test": X_test, "y_gesture_test": y_gesture_test,
                "y_chinese_test": y_chinese_test, "y_english_test": y_english_test
            }

            print(f"  è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬")
            print(f"  æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬")
            print("  æ³¨æ„: æœªåˆ›å»ºéªŒè¯é›†")

            return result

        except ValueError as e:
            print(f"æ•°æ®åˆ†å‰²å¤±è´¥: {e}")
            print("ä½¿ç”¨æ‰€æœ‰æ•°æ®ä½œä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†")
            return {
                "X_train": X, "y_gesture_train": y_gesture,
                "y_chinese_train": y_chinese, "y_english_train": y_english,
                "X_test": X, "y_gesture_test": y_gesture,
                "y_chinese_test": y_chinese, "y_english_test": y_english
            }

    def save_processed_data(self, data_splits: Dict, filename: str = None):
        """ä¿å­˜å¤„ç†åçš„æ•°æ®"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"processed_data_{timestamp}.pkl"

        filepath = os.path.join(self.processed_data_dir, filename)

        save_data = {
            "data_splits": data_splits,
            "scaler": self.scaler,
            "label_encoder": self.label_encoder,
            "label_decoder": self.label_decoder,
            "feature_config": self.feature_config,
            "stats": self.stats
        }

        with open(filepath, 'wb') as f:
            pickle.dump(save_data, f)

        print(f"å¤„ç†åçš„æ•°æ®å·²ä¿å­˜: {filepath}")
        return filepath

    def load_processed_data(self, filepath: str) -> Dict:
        """åŠ è½½å¤„ç†åçš„æ•°æ®"""
        with open(filepath, 'rb') as f:
            save_data = pickle.load(f)

        self.scaler = save_data["scaler"]
        self.label_encoder = save_data["label_encoder"]
        self.label_decoder = save_data["label_decoder"]
        self.feature_config = save_data["feature_config"]
        self.stats = save_data["stats"]
        self.is_scaler_fitted = True

        print(f"å¤„ç†åçš„æ•°æ®å·²åŠ è½½: {filepath}")
        return save_data["data_splits"]

    def visualize_data_distribution(self):
        """å¯è§†åŒ–æ•°æ®åˆ†å¸ƒ"""
        if not self.stats:
            print("æ²¡æœ‰ç»Ÿè®¡ä¿¡æ¯å¯ä¾›å¯è§†åŒ–")
            return

        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False

        fig, axes = plt.subplots(1, 3, figsize=(18, 6))

        # æ‰‹åŠ¿åˆ†å¸ƒ
        gesture_dist = self.stats["class_distribution"]["gesture"]
        if gesture_dist:
            labels = list(gesture_dist.keys())
            values = list(gesture_dist.values())

            bars1 = axes[0].bar(range(len(labels)), values, color='skyblue', alpha=0.8)
            axes[0].set_title("Gesture Label Distribution", fontsize=14, fontweight='bold')
            axes[0].set_xlabel("Gesture Labels", fontsize=12)
            axes[0].set_ylabel("Sample Count", fontsize=12)
            axes[0].set_xticks(range(len(labels)))
            axes[0].set_xticklabels(labels, rotation=45, ha='right')
            axes[0].grid(True, alpha=0.3)

            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, value in zip(bars1, values):
                axes[0].text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.05,
                             str(value), ha='center', va='bottom', fontweight='bold')

        # ä¸­æ–‡å«ä¹‰åˆ†å¸ƒ
        chinese_dist = self.stats["class_distribution"]["chinese"]
        if chinese_dist:
            labels = list(chinese_dist.keys())
            values = list(chinese_dist.values())

            bars2 = axes[1].bar(range(len(labels)), values, color='lightcoral', alpha=0.8)
            axes[1].set_title("Chinese Meaning Distribution", fontsize=14, fontweight='bold')
            axes[1].set_xlabel("Chinese Meanings", fontsize=12)
            axes[1].set_ylabel("Sample Count", fontsize=12)
            axes[1].set_xticks(range(len(labels)))
            axes[1].set_xticklabels(labels, rotation=45, ha='right', fontsize=10)
            axes[1].grid(True, alpha=0.3)

            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, value in zip(bars2, values):
                axes[1].text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.05,
                             str(value), ha='center', va='bottom', fontweight='bold')

        # è‹±æ–‡å«ä¹‰åˆ†å¸ƒ
        english_dist = self.stats["class_distribution"]["english"]
        if english_dist:
            labels = list(english_dist.keys())
            values = list(english_dist.values())

            bars3 = axes[2].bar(range(len(labels)), values, color='lightgreen', alpha=0.8)
            axes[2].set_title("English Meaning Distribution", fontsize=14, fontweight='bold')
            axes[2].set_xlabel("English Meanings", fontsize=12)
            axes[2].set_ylabel("Sample Count", fontsize=12)
            axes[2].set_xticks(range(len(labels)))
            axes[2].set_xticklabels(labels, rotation=45, ha='right', fontsize=10)
            axes[2].grid(True, alpha=0.3)

            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, value in zip(bars3, values):
                axes[2].text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.05,
                             str(value), ha='center', va='bottom', fontweight='bold')

        # è°ƒæ•´å¸ƒå±€
        plt.tight_layout()

        # ä¿å­˜å›¾è¡¨
        chart_path = os.path.join(self.processed_data_dir, "data_distribution.png")
        plt.savefig(chart_path, dpi=300, bbox_inches='tight', facecolor='white')

        # æ˜¾ç¤ºå›¾è¡¨
        plt.show()

    def print_text_distribution(self):
        """æ‰“å°æ–‡æœ¬ç‰ˆæ•°æ®åˆ†å¸ƒï¼ˆå½“å›¾å½¢æ˜¾ç¤ºå¤±è´¥æ—¶ä½¿ç”¨ï¼‰"""
        if not self.stats:
            print("æ²¡æœ‰ç»Ÿè®¡ä¿¡æ¯å¯æ˜¾ç¤º")
            return

        print("\n" + "=" * 60)
        print("ğŸ“Š æ•°æ®åˆ†å¸ƒç»Ÿè®¡")
        print("=" * 60)

        # æ€»ä½“ç»Ÿè®¡
        print(f"ğŸ“ˆ æ€»ä½“ä¿¡æ¯:")
        print(f"   æ€»æ ·æœ¬æ•°: {self.stats['total_samples']}")
        print(f"   åºåˆ—é•¿åº¦: {self.stats['sequence_length']}")
        print(f"   ç‰¹å¾ç»´åº¦: {self.stats['feature_dimension']}")
        print(f"   æ‰‹åŠ¿ç±»åˆ«æ•°: {self.stats['num_gesture_classes']}")

        # æ‰‹åŠ¿åˆ†å¸ƒ
        print(f"\nğŸ¤ æ‰‹åŠ¿æ ‡ç­¾åˆ†å¸ƒ:")
        gesture_dist = self.stats["class_distribution"]["gesture"]
        for label, count in sorted(gesture_dist.items()):
            percentage = (count / self.stats['total_samples']) * 100
            bar = "â–ˆ" * int(count * 20 / max(gesture_dist.values()))
            print(f"   {label:>3}: {count:>3} æ ·æœ¬ ({percentage:>5.1f}%) {bar}")

        # ä¸­æ–‡å«ä¹‰åˆ†å¸ƒ
        print(f"\nğŸˆ² ä¸­æ–‡å«ä¹‰åˆ†å¸ƒ:")
        chinese_dist = self.stats["class_distribution"]["chinese"]
        for label, count in sorted(chinese_dist.items()):
            percentage = (count / self.stats['total_samples']) * 100
            bar = "â–ˆ" * int(count * 20 / max(chinese_dist.values()))
            print(f"   {label:>6}: {count:>3} æ ·æœ¬ ({percentage:>5.1f}%) {bar}")

        # è‹±æ–‡å«ä¹‰åˆ†å¸ƒ
        print(f"\nğŸ”¤ è‹±æ–‡å«ä¹‰åˆ†å¸ƒ:")
        english_dist = self.stats["class_distribution"]["english"]
        for label, count in sorted(english_dist.items()):
            percentage = (count / self.stats['total_samples']) * 100
            bar = "â–ˆ" * int(count * 20 / max(english_dist.values()))
            print(f"   {label:>12}: {count:>3} æ ·æœ¬ ({percentage:>5.1f}%) {bar}")

        # æ•°æ®å¹³è¡¡æ€§åˆ†æ
        values = list(gesture_dist.values())
        if values:
            max_count = max(values)
            min_count = min(values)
            imbalance_ratio = max_count / min_count if min_count > 0 else float('inf')

            print(f"\nâš–ï¸  æ•°æ®å¹³è¡¡æ€§åˆ†æ:")
            print(f"   æœ€å¤šæ ·æœ¬æ•°: {max_count}")
            print(f"   æœ€å°‘æ ·æœ¬æ•°: {min_count}")
            print(f"   ä¸å¹³è¡¡æ¯”ç‡: {imbalance_ratio:.2f}")

            if imbalance_ratio > 3:
                print("   âš ï¸  æ•°æ®ä¸å¹³è¡¡è¾ƒä¸¥é‡ï¼Œå»ºè®®æ”¶é›†æ›´å¤šå°‘æ•°ç±»åˆ«çš„æ ·æœ¬")
            elif imbalance_ratio > 2:
                print("   âš ï¸  æ•°æ®å­˜åœ¨è½»å¾®ä¸å¹³è¡¡")
            else:
                print("   âœ… æ•°æ®åˆ†å¸ƒè¾ƒä¸ºå¹³è¡¡")

        print("=" * 60)

        # æ‰“å°è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“Š è¯¦ç»†æ•°æ®åˆ†å¸ƒ:")
        print("-" * 50)

        print("æ‰‹åŠ¿æ ‡ç­¾åˆ†å¸ƒ:")
        for label, count in gesture_dist.items():
            percentage = (count / self.stats['total_samples']) * 100
            print(f"  {label}: {count} æ ·æœ¬ ({percentage:.1f}%)")

        print("\nä¸­æ–‡å«ä¹‰åˆ†å¸ƒ:")
        for label, count in chinese_dist.items():
            percentage = (count / self.stats['total_samples']) * 100
            print(f"  {label}: {count} æ ·æœ¬ ({percentage:.1f}%)")

        print("\nè‹±æ–‡å«ä¹‰åˆ†å¸ƒ:")
        for label, count in english_dist.items():
            percentage = (count / self.stats['total_samples']) * 100
            print(f"  {label}: {count} æ ·æœ¬ ({percentage:.1f}%)")

        # æ£€æŸ¥æ•°æ®å¹³è¡¡æ€§
        values = list(gesture_dist.values())
        if values:
            max_count = max(values)
            min_count = min(values)
            imbalance_ratio = max_count / min_count if min_count > 0 else float('inf')

            print(f"\nğŸ“ˆ æ•°æ®å¹³è¡¡æ€§åˆ†æ:")
            print(f"  æœ€å¤šæ ·æœ¬æ•°: {max_count}")
            print(f"  æœ€å°‘æ ·æœ¬æ•°: {min_count}")
            print(f"  ä¸å¹³è¡¡æ¯”ç‡: {imbalance_ratio:.2f}")

            if imbalance_ratio > 3:
                print("  âš ï¸  æ•°æ®ä¸å¹³è¡¡è¾ƒä¸¥é‡ï¼Œå»ºè®®æ”¶é›†æ›´å¤šå°‘æ•°ç±»åˆ«çš„æ ·æœ¬")
            elif imbalance_ratio > 2:
                print("  âš ï¸  æ•°æ®å­˜åœ¨è½»å¾®ä¸å¹³è¡¡")
            else:
                print("  âœ… æ•°æ®åˆ†å¸ƒè¾ƒä¸ºå¹³è¡¡")


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºæ•°æ®é¢„å¤„ç†æµç¨‹"""
    print("æ‰‹è¯­æ•°æ®é¢„å¤„ç†å™¨")
    print("=" * 50)

    # åˆ›å»ºé¢„å¤„ç†å™¨
    preprocessor = HandGesturePreprocessor()

    # æ£€æŸ¥æ˜¯å¦æœ‰åŸå§‹æ•°æ®
    raw_data_files = []
    if os.path.exists(preprocessor.raw_data_dir):
        raw_data_files = [f for f in os.listdir(preprocessor.raw_data_dir) if f.endswith('.json')]

    if not raw_data_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°åŸå§‹æ•°æ®æ–‡ä»¶")
        print("\nğŸ“‹ è¯·å…ˆæ”¶é›†æ•°æ®:")
        print("1. è¿è¡Œ data_collector.py")
        print("2. æŒ‰æ•°å­—é”®(0-9)å½•åˆ¶è‡³å°‘10ä¸ªä¸åŒçš„æ‰‹åŠ¿")
        print("3. æ¯ä¸ªæ‰‹åŠ¿å»ºè®®å½•åˆ¶5-10æ¬¡")
        print("4. ç„¶åå†è¿è¡Œæ­¤é¢„å¤„ç†ç¨‹åº")
        return

    print(f"âœ… æ‰¾åˆ° {len(raw_data_files)} ä¸ªåŸå§‹æ•°æ®æ–‡ä»¶")

    try:
        # å¤„ç†æ‰€æœ‰æ•°æ®
        X, y_gesture, y_chinese, y_english = preprocessor.process_all_data()

        if len(X) == 0:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„æ•°æ®å¯ä»¥å¤„ç†")
            return

        # åˆ†å‰²æ•°æ®
        print("\nå¼€å§‹åˆ†å‰²æ•°æ®...")
        data_splits = preprocessor.split_data(X, y_gesture, y_chinese, y_english)

        # ä¿å­˜å¤„ç†åçš„æ•°æ®
        save_path = preprocessor.save_processed_data(data_splits)

        # å¯è§†åŒ–æ•°æ®åˆ†å¸ƒ
        print("\nç”Ÿæˆæ•°æ®åˆ†å¸ƒå›¾...")
        try:
            preprocessor.visualize_data_distribution()
        except Exception as e:
            print(f"å›¾å½¢å¯è§†åŒ–å¤±è´¥: {e}")
            print("ç”Ÿæˆæ–‡æœ¬ç‰ˆæ•°æ®åˆ†å¸ƒ...")
            preprocessor.print_text_distribution()

        print(f"\nâœ… æ•°æ®é¢„å¤„ç†å®Œæˆ!")
        print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"   æ€»æ ·æœ¬æ•°: {len(X)}")
        print(f"   åºåˆ—é•¿åº¦: {X.shape[1]}")
        print(f"   ç‰¹å¾ç»´åº¦: {X.shape[2]}")
        print(f"   æ‰‹åŠ¿ç±»åˆ«: {len(preprocessor.label_encoder['gesture'])}")

        print(f"\nğŸ“ æ•°æ®é›†åˆ’åˆ†:")
        print(f"   è®­ç»ƒé›†: {data_splits['X_train'].shape[0]} æ ·æœ¬")
        if 'X_val' in data_splits:
            print(f"   éªŒè¯é›†: {data_splits['X_val'].shape[0]} æ ·æœ¬")
        print(f"   æµ‹è¯•é›†: {data_splits['X_test'].shape[0]} æ ·æœ¬")

        print(f"\nğŸ’¾ æ–‡ä»¶ä¿å­˜ä½ç½®:")
        print(f"   å¤„ç†åæ•°æ®: {save_path}")
        print(f"   æ•°æ®åˆ†å¸ƒå›¾: {os.path.join(preprocessor.processed_data_dir, 'data_distribution.png')}")

        print(f"\nğŸš€ ä¸‹ä¸€æ­¥:")
        print("   ç°åœ¨å¯ä»¥è¿è¡Œ trainer.py å¼€å§‹è®­ç»ƒæ¨¡å‹")

        if len(X) < 10:
            print(f"\nâš ï¸  å»ºè®®:")
            print("   å½“å‰æ•°æ®é‡è¾ƒå°‘ï¼Œå»ºè®®:")
            print("   1. æ”¶é›†æ›´å¤šè®­ç»ƒæ•°æ® (æ¯ä¸ªæ‰‹åŠ¿è‡³å°‘10-20ä¸ªæ ·æœ¬)")
            print("   2. å¢åŠ æ‰‹åŠ¿ç±»åˆ«çš„å¤šæ ·æ€§")
            print("   3. åœ¨ä¸åŒæ¡ä»¶ä¸‹æ”¶é›†æ•°æ®")

    except Exception as e:
        print(f"âŒ æ•°æ®é¢„å¤„ç†å¤±è´¥: {e}")
        print(f"\nğŸ”§ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
        print("1. æ£€æŸ¥åŸå§‹æ•°æ®æ–‡ä»¶æ˜¯å¦å®Œæ•´")
        print("2. ç¡®ä¿è‡³å°‘æœ‰1ä¸ªæœ‰æ•ˆçš„æ‰‹åŠ¿æ•°æ®")
        print("3. æ£€æŸ¥æ•°æ®æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®")
        print("4. é‡æ–°è¿è¡Œ data_collector.py æ”¶é›†æ•°æ®")


if __name__ == "__main__":
    main()