# -*- coding: utf-8 -*- 
# @Time    : 2025/6/28 16:08
# @Author  : yigeoooo
# @FileName: enhanced_trainer.py
# @Software: PyCharm
"""
å¢å¼ºè®­ç»ƒå™¨ - ä¸“é—¨è§£å†³ä¸¤ç±»åˆ†ç±»é—®é¢˜
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
import os
from datetime import datetime

from trainer import HandGestureTrainer
from data_preprocessor import HandGesturePreprocessor


def enhanced_training():
    """å¢å¼ºçš„è®­ç»ƒæµç¨‹ï¼Œä¸“é—¨é’ˆå¯¹ä¸¤ç±»åˆ†ç±»é—®é¢˜"""
    print("ğŸš€ å¢å¼ºè®­ç»ƒå™¨ - ä¸“é—¨è§£å†³ä¸¤ç±»åˆ†ç±»é—®é¢˜")
    print("=" * 60)

    # 1. æ£€æŸ¥æ•°æ®
    data_dir = "data/processed"
    processed_files = [f for f in os.listdir(data_dir) if f.endswith('.pkl')]
    if not processed_files:
        print("âŒ æ‰¾ä¸åˆ°é¢„å¤„ç†æ•°æ®æ–‡ä»¶")
        return

    latest_file = sorted(processed_files)[-1]
    data_path = os.path.join(data_dir, latest_file)
    print(f"âœ… ä½¿ç”¨æ•°æ®æ–‡ä»¶: {latest_file}")

    # 2. åŠ è½½æ•°æ®
    preprocessor = HandGesturePreprocessor()
    data_splits = preprocessor.load_processed_data(data_path)

    # 3. åˆ†ææ•°æ®è´¨é‡
    X_train = data_splits['X_train']
    y_train = data_splits['y_gesture_train']

    unique_classes, class_counts = np.unique(y_train, return_counts=True)
    print(f"\nğŸ“Š æ•°æ®åˆ†æ:")
    print(f"   ç±»åˆ«æ•°: {len(unique_classes)}")
    print(f"   è®­ç»ƒæ ·æœ¬: {len(X_train)}")

    for cls, count in zip(unique_classes, class_counts):
        gesture_name = preprocessor.label_decoder['gesture'].get(cls, f'æœªçŸ¥_{cls}')
        print(f"   ç±»åˆ«{cls}({gesture_name}): {count} æ ·æœ¬")

    # è®¡ç®—ç±»åˆ«æƒé‡æ¥å¤„ç†ä¸å¹³è¡¡
    class_weights = len(y_train) / (len(unique_classes) * class_counts)
    weight_dict = {cls: weight for cls, weight in zip(unique_classes, class_weights)}
    print(f"\nâš–ï¸ è®¡ç®—ç±»åˆ«æƒé‡: {weight_dict}")

    # 4. åˆ›å»ºå¤šä¸ªè®­ç»ƒå®éªŒ
    experiments = [
        {
            'name': 'LSTM_é«˜å­¦ä¹ ç‡',
            'model_type': 'lstm',
            'model_params': {'hidden_dim': 256, 'num_layers': 3, 'dropout': 0.5},
            'lr': 0.01,
            'epochs': 150,
            'scheduler': 'step'
        },
        {
            'name': 'CNN_LSTM_æ··åˆ',
            'model_type': 'cnn_lstm',
            'model_params': {'cnn_hidden_dims': [256, 512], 'lstm_hidden_dim': 256, 'dropout': 0.4},
            'lr': 0.005,
            'epochs': 150,
            'scheduler': 'cosine'
        },
        {
            'name': 'Transformer_æ³¨æ„åŠ›',
            'model_type': 'transformer',
            'model_params': {'d_model': 512, 'nhead': 8, 'num_layers': 4},
            'lr': 0.001,
            'epochs': 200,
            'scheduler': 'plateau'
        }
    ]

    best_result = {'accuracy': 0, 'model_name': '', 'model_path': ''}

    for i, exp in enumerate(experiments):
        print(f"\n{'=' * 20} å®éªŒ {i + 1}: {exp['name']} {'=' * 20}")

        try:
            # åˆ›å»ºè®­ç»ƒå™¨
            trainer = HandGestureTrainer(model_type=exp['model_type'])
            trainer.prepare_data(data_splits, batch_size=8)  # å°æ‰¹æ¬¡é€‚åˆå°æ•°æ®é›†

            # æ„å»ºæ¨¡å‹
            trainer.build_model(**exp['model_params'])

            # è®¾ç½®å¸¦ç±»åˆ«æƒé‡çš„æŸå¤±å‡½æ•°
            if hasattr(trainer, 'criterion') and hasattr(trainer.criterion, 'weight'):
                weights = torch.FloatTensor([weight_dict.get(i, 1.0) for i in range(len(unique_classes))])
                trainer.criterion = nn.CrossEntropyLoss(weight=weights, label_smoothing=0.1)

            # è®¾ç½®è®­ç»ƒå‚æ•°
            trainer.setup_training(
                learning_rate=exp['lr'],
                optimizer_type="adam",
                scheduler_type=exp['scheduler'],
                weight_decay=1e-3,
                use_early_stopping=True,
                patience=30
            )

            # è®­ç»ƒ
            print(f"å¼€å§‹è®­ç»ƒ {exp['name']}...")
            trainer.train(epochs=exp['epochs'], verbose=True)

            # è¯„ä¼°
            results = trainer.evaluate()
            accuracy = results['accuracy']

            print(f"\nâœ… {exp['name']} å®Œæˆ:")
            print(f"   æœ€ç»ˆå‡†ç¡®ç‡: {accuracy:.4f}")
            print(f"   å¹³å‡æŸå¤±: {results['avg_loss']:.4f}")

            # ä¿å­˜æ¨¡å‹
            model_path = f"data/models/{exp['name']}_final.pth"
            trainer.save_checkpoint(exp['epochs'], is_best=True)

            # è®°å½•æœ€ä½³ç»“æœ
            if accuracy > best_result['accuracy']:
                best_result = {
                    'accuracy': accuracy,
                    'model_name': exp['name'],
                    'model_path': model_path
                }

            # åˆ†æè®­ç»ƒè´¨é‡
            analyze_training_quality(trainer, exp['name'])

        except Exception as e:
            print(f"âŒ {exp['name']} è®­ç»ƒå¤±è´¥: {e}")
            continue

    # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
    print(f"\nğŸ† æœ€ä½³æ¨¡å‹ç»“æœ:")
    print(f"   æ¨¡å‹: {best_result['model_name']}")
    print(f"   å‡†ç¡®ç‡: {best_result['accuracy']:.4f}")

    if best_result['accuracy'] > 0.8:
        print(f"âœ… è®­ç»ƒæˆåŠŸ! æ¨¡å‹å‡†ç¡®ç‡è¶…è¿‡80%")
    elif best_result['accuracy'] > 0.6:
        print(f"âš ï¸ è®­ç»ƒä¸€èˆ¬ï¼Œå‡†ç¡®ç‡{best_result['accuracy']:.1%}ï¼Œå¯èƒ½éœ€è¦æ›´å¤šæ•°æ®")
    else:
        print(f"âŒ è®­ç»ƒæ•ˆæœå·®ï¼Œå‡†ç¡®ç‡ä»…{best_result['accuracy']:.1%}")
        print(f"ğŸ’¡ å»ºè®®:")
        print(f"   1. æ£€æŸ¥æ‰‹åŠ¿æ˜¯å¦è¶³å¤Ÿä¸åŒ")
        print(f"   2. é‡æ–°æ”¶é›†æ›´å¤šé«˜è´¨é‡æ•°æ®")
        print(f"   3. ç¡®ä¿æ‰‹åŠ¿åŠ¨ä½œæ ‡å‡†åŒ–")


def analyze_training_quality(trainer, model_name):
    """åˆ†æè®­ç»ƒè´¨é‡"""
    history = trainer.metrics_tracker.history

    if not history.get('train_acc') or not history.get('val_acc'):
        return

    final_train_acc = history['train_acc'][-1] if history['train_acc'] else 0
    final_val_acc = history['val_acc'][-1] if history['val_acc'] else 0

    print(f"\nğŸ“ˆ {model_name} è®­ç»ƒè´¨é‡åˆ†æ:")
    print(f"   æœ€ç»ˆè®­ç»ƒå‡†ç¡®ç‡: {final_train_acc:.4f}")
    print(f"   æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {final_val_acc:.4f}")

    # è¿‡æ‹Ÿåˆæ£€æŸ¥
    overfitting = final_train_acc - final_val_acc
    if overfitting > 0.2:
        print(f"   âš ï¸ ä¸¥é‡è¿‡æ‹Ÿåˆ (å·®è·: {overfitting:.3f})")
    elif overfitting > 0.1:
        print(f"   âš ï¸ è½»å¾®è¿‡æ‹Ÿåˆ (å·®è·: {overfitting:.3f})")
    else:
        print(f"   âœ… æ³›åŒ–è‰¯å¥½ (å·®è·: {overfitting:.3f})")

    # æ”¶æ•›æ€§æ£€æŸ¥
    if len(history['train_acc']) > 20:
        recent_improvement = history['train_acc'][-1] - history['train_acc'][-10]
        if abs(recent_improvement) < 0.01:
            print(f"   âœ… å·²æ”¶æ•›")
        else:
            print(f"   ğŸ”„ ä»åœ¨æ”¹å–„")

    # å­¦ä¹ ç‡æ£€æŸ¥
    if history.get('learning_rate'):
        final_lr = history['learning_rate'][-1]
        print(f"   æœ€ç»ˆå­¦ä¹ ç‡: {final_lr:.6f}")


def quick_fix_training():
    """å¿«é€Ÿä¿®å¤è®­ç»ƒ - é’ˆå¯¹å½“å‰é—®é¢˜çš„ç®€åŒ–ç‰ˆæœ¬"""
    print("ğŸ”§ å¿«é€Ÿä¿®å¤è®­ç»ƒ")
    print("=" * 40)

    # 1. åŠ è½½æ•°æ®
    data_dir = "data/processed"
    processed_files = [f for f in os.listdir(data_dir) if f.endswith('.pkl')]
    latest_file = sorted(processed_files)[-1]
    data_path = os.path.join(data_dir, latest_file)

    preprocessor = HandGesturePreprocessor()
    data_splits = preprocessor.load_processed_data(data_path)

    # 2. ç®€å•ä½†æœ‰æ•ˆçš„è®­ç»ƒ
    trainer = HandGestureTrainer(model_type="lstm")
    trainer.prepare_data(data_splits, batch_size=4)  # å¾ˆå°çš„æ‰¹æ¬¡

    # 3. å°æ¨¡å‹ï¼Œé«˜å­¦ä¹ ç‡
    trainer.build_model(
        hidden_dim=128,
        num_layers=2,
        dropout=0.3,
        bidirectional=True
    )

    # 4. æ¿€è¿›çš„è®­ç»ƒè®¾ç½®
    trainer.optimizer = optim.SGD(trainer.model.parameters(), lr=0.1, momentum=0.9)
    trainer.criterion = nn.CrossEntropyLoss()
    trainer.scheduler = optim.lr_scheduler.StepLR(trainer.optimizer, step_size=50, gamma=0.1)

    print("å¼€å§‹æ¿€è¿›è®­ç»ƒ...")

    # 5. è®­ç»ƒæ›´å¤šè½®æ¬¡
    for epoch in range(300):
        trainer.model.train()
        total_loss = 0
        correct = 0
        total = 0

        for batch_idx, (inputs, labels) in enumerate(trainer.train_loader):
            inputs, labels = inputs.to(trainer.device), labels.to(trainer.device)

            trainer.optimizer.zero_grad()
            outputs = trainer.model(inputs)
            loss = trainer.criterion(outputs, labels)
            loss.backward()
            trainer.optimizer.step()

            total_loss += loss.item()
            pred = torch.argmax(outputs, dim=1)
            correct += (pred == labels).sum().item()
            total += labels.size(0)

        if trainer.scheduler:
            trainer.scheduler.step()

        accuracy = correct / total

        if epoch % 20 == 0:
            print(f"Epoch {epoch}: Loss={total_loss / len(trainer.train_loader):.4f}, Acc={accuracy:.4f}")

        # å¦‚æœå‡†ç¡®ç‡è¾¾åˆ°95%ä»¥ä¸Šå°±åœæ­¢
        if accuracy > 0.95:
            print(f"âœ… åœ¨ç¬¬{epoch}è½®è¾¾åˆ°95%å‡†ç¡®ç‡ï¼Œåœæ­¢è®­ç»ƒ")
            break

    # ä¿å­˜æ¨¡å‹
    torch.save({
        'model_state_dict': trainer.model.state_dict(),
        'model_type': 'lstm'
    }, 'data/models/quick_fix_model.pth')

    # è¯„ä¼°
    results = trainer.evaluate()
    print(f"\næœ€ç»ˆç»“æœ: å‡†ç¡®ç‡ {results['accuracy']:.4f}")

    return results['accuracy']


def main():
    """ä¸»å‡½æ•°"""
    import sys

    if len(sys.argv) > 1 and sys.argv[1] == "quick":
        accuracy = quick_fix_training()
        if accuracy > 0.8:
            print("âœ… å¿«é€Ÿä¿®å¤æˆåŠŸ!")
        else:
            print("âŒ å¿«é€Ÿä¿®å¤å¤±è´¥ï¼Œå°è¯•å®Œæ•´å¢å¼ºè®­ç»ƒ")
            enhanced_training()
    else:
        enhanced_training()


if __name__ == "__main__":
    main()