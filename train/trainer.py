import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
import os
import json
import time
from datetime import datetime
from typing import Dict, List, Tuple, Optional, Any
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import pickle
from tqdm import tqdm
import warnings

warnings.filterwarnings('ignore')

from model_definition import ModelFactory, count_parameters


class EarlyStopping:
    """æ—©åœæœºåˆ¶"""

    def __init__(self, patience: int = 7, min_delta: float = 0.001, restore_best_weights: bool = True):
        self.patience = patience
        self.min_delta = min_delta
        self.restore_best_weights = restore_best_weights
        self.best_loss = float('inf')
        self.counter = 0
        self.best_weights = None

    def __call__(self, val_loss: float, model: nn.Module) -> bool:
        if val_loss < self.best_loss - self.min_delta:
            self.best_loss = val_loss
            self.counter = 0
            if self.restore_best_weights:
                self.best_weights = model.state_dict().copy()
        else:
            self.counter += 1

        if self.counter >= self.patience:
            if self.restore_best_weights and self.best_weights:
                model.load_state_dict(self.best_weights)
            return True
        return False


class MetricsTracker:
    """æŒ‡æ ‡è·Ÿè¸ªå™¨"""

    def __init__(self):
        self.reset()

    def reset(self):
        self.history = {
            'train_loss': [],
            'val_loss': [],
            'train_acc': [],
            'val_acc': [],
            'learning_rate': []
        }

    def update(self, metrics: Dict[str, float]):
        for key, value in metrics.items():
            if key in self.history:
                self.history[key].append(value)

    def get_best_epoch(self, metric: str = 'val_acc', mode: str = 'max') -> int:
        if metric not in self.history or not self.history[metric]:
            return 0

        if mode == 'max':
            return np.argmax(self.history[metric])
        else:
            return np.argmin(self.history[metric])

    def plot_history(self, save_path: str = None):
        """ç»˜åˆ¶è®­ç»ƒå†å²"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))

        # æŸå¤±æ›²çº¿
        axes[0, 0].plot(self.history['train_loss'], label='Training Loss', color='blue')
        if self.history['val_loss']:
            axes[0, 0].plot(self.history['val_loss'], label='Validation Loss', color='red')
        axes[0, 0].set_title('Model Loss')
        axes[0, 0].set_xlabel('Epoch')
        axes[0, 0].set_ylabel('Loss')
        axes[0, 0].legend()
        axes[0, 0].grid(True)

        # å‡†ç¡®ç‡æ›²çº¿
        axes[0, 1].plot(self.history['train_acc'], label='Training Accuracy', color='blue')
        if self.history['val_acc']:
            axes[0, 1].plot(self.history['val_acc'], label='Validation Accuracy', color='red')
        axes[0, 1].set_title('Model Accuracy')
        axes[0, 1].set_xlabel('Epoch')
        axes[0, 1].set_ylabel('Accuracy')
        axes[0, 1].legend()
        axes[0, 1].grid(True)

        # å­¦ä¹ ç‡æ›²çº¿
        if self.history['learning_rate']:
            axes[1, 0].plot(self.history['learning_rate'], label='Learning Rate', color='green')
            axes[1, 0].set_title('Learning Rate')
            axes[1, 0].set_xlabel('Epoch')
            axes[1, 0].set_ylabel('Learning Rate')
            axes[1, 0].legend()
            axes[1, 0].grid(True)
            axes[1, 0].set_yscale('log')

        # éªŒè¯æŸå¤±vsè®­ç»ƒæŸå¤±
        if self.history['val_loss']:
            axes[1, 1].scatter(self.history['train_loss'], self.history['val_loss'], alpha=0.6)
            axes[1, 1].plot([0, max(self.history['train_loss'])], [0, max(self.history['train_loss'])], 'r--')
            axes[1, 1].set_title('Validation vs Training Loss')
            axes[1, 1].set_xlabel('Training Loss')
            axes[1, 1].set_ylabel('Validation Loss')
            axes[1, 1].grid(True)

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"è®­ç»ƒå†å²å›¾å·²ä¿å­˜: {save_path}")

        plt.show()


class HandGestureTrainer:
    """æ‰‹è¯­è¯†åˆ«è®­ç»ƒå™¨"""

    def __init__(self, model_type: str = "lstm", device: str = None, save_dir: str = "data/models"):
        self.model_type = model_type
        self.device = device if device else torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.save_dir = save_dir

        # åˆ›å»ºä¿å­˜ç›®å½•ï¼ˆç¡®ä¿è·¯å¾„å­˜åœ¨ï¼‰
        os.makedirs(self.save_dir, exist_ok=True)
        print(f"æ¨¡å‹ä¿å­˜ç›®å½•: {os.path.abspath(self.save_dir)}")

        # æ¨¡å‹å’Œä¼˜åŒ–å™¨
        self.model = None
        self.optimizer = None
        self.scheduler = None
        self.criterion = None

        # è®­ç»ƒçŠ¶æ€
        self.is_multitask = False
        self.metrics_tracker = MetricsTracker()
        self.early_stopping = None

        # æ•°æ®
        self.train_loader = None
        self.val_loader = None
        self.test_loader = None

        print(f"è®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨è®¾å¤‡: {self.device}")

    def prepare_data(self, data_splits: Dict, batch_size: int = 32, shuffle: bool = True):
        """å‡†å¤‡æ•°æ®åŠ è½½å™¨"""
        print("å‡†å¤‡æ•°æ®åŠ è½½å™¨...")

        # è®­ç»ƒæ•°æ®
        train_dataset = TensorDataset(
            torch.FloatTensor(data_splits['X_train']),
            torch.LongTensor(data_splits['y_gesture_train'])
        )
        self.train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)

        # éªŒè¯æ•°æ®
        if 'X_val' in data_splits:
            val_dataset = TensorDataset(
                torch.FloatTensor(data_splits['X_val']),
                torch.LongTensor(data_splits['y_gesture_val'])
            )
            self.val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

        # æµ‹è¯•æ•°æ®
        test_dataset = TensorDataset(
            torch.FloatTensor(data_splits['X_test']),
            torch.LongTensor(data_splits['y_gesture_test'])
        )
        self.test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

        # è·å–æ•°æ®ç»´åº¦ä¿¡æ¯
        sample_batch = next(iter(self.train_loader))
        self.input_dim = sample_batch[0].shape[-1]
        self.sequence_length = sample_batch[0].shape[1]
        self.num_classes = len(torch.unique(sample_batch[1]))

        print(f"æ•°æ®åŠ è½½å™¨å‡†å¤‡å®Œæˆ:")
        print(f"  è®­ç»ƒé›†: {len(self.train_loader.dataset)} æ ·æœ¬")
        if self.val_loader:
            print(f"  éªŒè¯é›†: {len(self.val_loader.dataset)} æ ·æœ¬")
        print(f"  æµ‹è¯•é›†: {len(self.test_loader.dataset)} æ ·æœ¬")
        print(f"  è¾“å…¥ç»´åº¦: {self.input_dim}")
        print(f"  åºåˆ—é•¿åº¦: {self.sequence_length}")
        print(f"  ç±»åˆ«æ•°: {self.num_classes}")

    def prepare_multitask_data(self, data_splits: Dict, batch_size: int = 32, shuffle: bool = True):
        """å‡†å¤‡å¤šä»»åŠ¡æ•°æ®åŠ è½½å™¨"""
        print("å‡†å¤‡å¤šä»»åŠ¡æ•°æ®åŠ è½½å™¨...")

        self.is_multitask = True

        # è®­ç»ƒæ•°æ®
        train_dataset = TensorDataset(
            torch.FloatTensor(data_splits['X_train']),
            torch.LongTensor(data_splits['y_gesture_train']),
            torch.LongTensor(data_splits['y_chinese_train']),
            torch.LongTensor(data_splits['y_english_train'])
        )
        self.train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)

        # éªŒè¯æ•°æ®
        if 'X_val' in data_splits:
            val_dataset = TensorDataset(
                torch.FloatTensor(data_splits['X_val']),
                torch.LongTensor(data_splits['y_gesture_val']),
                torch.LongTensor(data_splits['y_chinese_val']),
                torch.LongTensor(data_splits['y_english_val'])
            )
            self.val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

        # æµ‹è¯•æ•°æ®
        test_dataset = TensorDataset(
            torch.FloatTensor(data_splits['X_test']),
            torch.LongTensor(data_splits['y_gesture_test']),
            torch.LongTensor(data_splits['y_chinese_test']),
            torch.LongTensor(data_splits['y_english_test'])
        )
        self.test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

        # è·å–æ•°æ®ç»´åº¦ä¿¡æ¯
        sample_batch = next(iter(self.train_loader))
        self.input_dim = sample_batch[0].shape[-1]
        self.sequence_length = sample_batch[0].shape[1]
        self.num_gesture_classes = len(torch.unique(sample_batch[1]))
        self.num_chinese_classes = len(torch.unique(sample_batch[2]))
        self.num_english_classes = len(torch.unique(sample_batch[3]))

        print(f"å¤šä»»åŠ¡æ•°æ®åŠ è½½å™¨å‡†å¤‡å®Œæˆ:")
        print(f"  æ‰‹åŠ¿ç±»åˆ«æ•°: {self.num_gesture_classes}")
        print(f"  ä¸­æ–‡ç±»åˆ«æ•°: {self.num_chinese_classes}")
        print(f"  è‹±æ–‡ç±»åˆ«æ•°: {self.num_english_classes}")

    def build_model(self, **model_kwargs):
        """æ„å»ºæ¨¡å‹"""
        print(f"æ„å»º{self.model_type}æ¨¡å‹...")

        if self.model_type == "multitask":
            if not self.is_multitask:
                raise ValueError("å¤šä»»åŠ¡æ¨¡å‹éœ€è¦ä½¿ç”¨prepare_multitask_dataå‡†å¤‡æ•°æ®")

            self.model = ModelFactory.create_model(
                self.model_type,
                input_dim=self.input_dim,
                num_gesture_classes=self.num_gesture_classes,
                num_chinese_classes=self.num_chinese_classes,
                num_english_classes=self.num_english_classes,
                **model_kwargs
            )
        else:
            self.model = ModelFactory.create_model(
                self.model_type,
                input_dim=self.input_dim,
                num_classes=self.num_classes,
                **model_kwargs
            )

        self.model.to(self.device)

        # æ‰“å°æ¨¡å‹ä¿¡æ¯
        total_params = count_parameters(self.model)
        print(f"æ¨¡å‹æ„å»ºå®Œæˆ:")
        print(f"  æ¨¡å‹ç±»å‹: {self.model_type}")
        print(f"  æ€»å‚æ•°æ•°: {total_params:,}")
        print(f"  æ¨¡å‹å¤§å°: {total_params * 4 / (1024 * 1024):.2f} MB")

    def setup_training(self, learning_rate: float = 0.01, optimizer_type: str = "adam",
                       scheduler_type: str = "cosine", weight_decay: float = 1e-4,
                       use_early_stopping: bool = True, patience: int = 20):
        """è®¾ç½®è®­ç»ƒå‚æ•°"""
        print("è®¾ç½®è®­ç»ƒå‚æ•°...")

        # æŸå¤±å‡½æ•° - ä½¿ç”¨æ ‡ç­¾å¹³æ»‘å‡å°‘è¿‡æ‹Ÿåˆ
        if self.is_multitask:
            self.criterion = {
                'gesture': nn.CrossEntropyLoss(label_smoothing=0.1),
                'chinese': nn.CrossEntropyLoss(label_smoothing=0.1),
                'english': nn.CrossEntropyLoss(label_smoothing=0.1)
            }
        else:
            self.criterion = nn.CrossEntropyLoss(label_smoothing=0.1)

        # ä¼˜åŒ–å™¨ - ä½¿ç”¨æ›´é«˜çš„å­¦ä¹ ç‡
        if optimizer_type.lower() == "adam":
            self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate, weight_decay=weight_decay)
        elif optimizer_type.lower() == "adamw":
            self.optimizer = optim.AdamW(self.model.parameters(), lr=learning_rate, weight_decay=weight_decay)
        elif optimizer_type.lower() == "sgd":
            self.optimizer = optim.SGD(self.model.parameters(), lr=learning_rate,
                                       momentum=0.9, weight_decay=weight_decay)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ä¼˜åŒ–å™¨ç±»å‹: {optimizer_type}")

        # å­¦ä¹ ç‡è°ƒåº¦å™¨ - ä½¿ç”¨æ›´æ¿€è¿›çš„è°ƒåº¦
        if scheduler_type.lower() == "cosine":
            self.scheduler = optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=50, eta_min=1e-6)
        elif scheduler_type.lower() == "step":
            self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=20, gamma=0.5)
        elif scheduler_type.lower() == "plateau":
            self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode='min',
                                                                  factor=0.5, patience=8, min_lr=1e-6)
        elif scheduler_type.lower() == "none":
            self.scheduler = None
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„è°ƒåº¦å™¨ç±»å‹: {scheduler_type}")

        # æ—©åœ - å¢åŠ è€å¿ƒå€¼
        if use_early_stopping:
            self.early_stopping = EarlyStopping(patience=patience, min_delta=0.001)

        print(f"è®­ç»ƒè®¾ç½®å®Œæˆ:")
        print(f"  ä¼˜åŒ–å™¨: {optimizer_type}")
        print(f"  å­¦ä¹ ç‡: {learning_rate}")
        print(f"  è°ƒåº¦å™¨: {scheduler_type}")
        print(f"  æ—©åœè€å¿ƒ: {patience}")
        print(f"  æ ‡ç­¾å¹³æ»‘: 0.1")

    def train_epoch(self) -> Dict[str, float]:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()

        total_loss = 0.0
        correct_predictions = 0
        total_samples = 0

        if self.is_multitask:
            task_losses = {'gesture': 0.0, 'chinese': 0.0, 'english': 0.0}
            task_correct = {'gesture': 0, 'chinese': 0, 'english': 0}

        progress_bar = tqdm(self.train_loader, desc="è®­ç»ƒä¸­")

        for batch_idx, batch in enumerate(progress_bar):
            if self.is_multitask:
                inputs, gesture_labels, chinese_labels, english_labels = batch
                inputs = inputs.to(self.device)
                gesture_labels = gesture_labels.to(self.device)
                chinese_labels = chinese_labels.to(self.device)
                english_labels = english_labels.to(self.device)

                # å‰å‘ä¼ æ’­
                outputs = self.model(inputs)

                # è®¡ç®—æŸå¤±
                losses = {
                    'gesture': self.criterion['gesture'](outputs['gesture'], gesture_labels),
                    'chinese': self.criterion['chinese'](outputs['chinese'], chinese_labels),
                    'english': self.criterion['english'](outputs['english'], english_labels)
                }

                # æ€»æŸå¤±ï¼ˆå¯ä»¥åŠ æƒï¼‰
                total_batch_loss = losses['gesture'] + losses['chinese'] + losses['english']

                # è®¡ç®—å‡†ç¡®ç‡
                for task in ['gesture', 'chinese', 'english']:
                    pred = torch.argmax(outputs[task], dim=1)
                    if task == 'gesture':
                        correct = (pred == gesture_labels).sum().item()
                    elif task == 'chinese':
                        correct = (pred == chinese_labels).sum().item()
                    else:
                        correct = (pred == english_labels).sum().item()

                    task_correct[task] += correct
                    task_losses[task] += losses[task].item()

                correct_predictions += task_correct['gesture']  # ä»¥æ‰‹åŠ¿ä»»åŠ¡ä¸ºä¸»è¦æŒ‡æ ‡

            else:
                inputs, labels = batch
                inputs = inputs.to(self.device)
                labels = labels.to(self.device)

                # å‰å‘ä¼ æ’­
                outputs = self.model(inputs)
                total_batch_loss = self.criterion(outputs, labels)

                # è®¡ç®—å‡†ç¡®ç‡
                pred = torch.argmax(outputs, dim=1)
                correct_predictions += (pred == labels).sum().item()

            # åå‘ä¼ æ’­
            self.optimizer.zero_grad()
            total_batch_loss.backward()
            self.optimizer.step()

            total_loss += total_batch_loss.item()
            total_samples += inputs.size(0)

            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.set_postfix({
                'Loss': f'{total_batch_loss.item():.4f}',
                'Acc': f'{correct_predictions / total_samples:.4f}'
            })

        avg_loss = total_loss / len(self.train_loader)
        avg_acc = correct_predictions / total_samples

        metrics = {'train_loss': avg_loss, 'train_acc': avg_acc}

        if self.is_multitask:
            for task in ['gesture', 'chinese', 'english']:
                metrics[f'train_{task}_loss'] = task_losses[task] / len(self.train_loader)
                metrics[f'train_{task}_acc'] = task_correct[task] / total_samples

        return metrics

    def validate_epoch(self) -> Dict[str, float]:
        """éªŒè¯ä¸€ä¸ªepoch"""
        if not self.val_loader:
            return {}

        self.model.eval()

        total_loss = 0.0
        correct_predictions = 0
        total_samples = 0

        if self.is_multitask:
            task_losses = {'gesture': 0.0, 'chinese': 0.0, 'english': 0.0}
            task_correct = {'gesture': 0, 'chinese': 0, 'english': 0}

        with torch.no_grad():
            for batch in self.val_loader:
                if self.is_multitask:
                    inputs, gesture_labels, chinese_labels, english_labels = batch
                    inputs = inputs.to(self.device)
                    gesture_labels = gesture_labels.to(self.device)
                    chinese_labels = chinese_labels.to(self.device)
                    english_labels = english_labels.to(self.device)

                    outputs = self.model(inputs)

                    losses = {
                        'gesture': self.criterion['gesture'](outputs['gesture'], gesture_labels),
                        'chinese': self.criterion['chinese'](outputs['chinese'], chinese_labels),
                        'english': self.criterion['english'](outputs['english'], english_labels)
                    }

                    total_batch_loss = losses['gesture'] + losses['chinese'] + losses['english']

                    for task in ['gesture', 'chinese', 'english']:
                        pred = torch.argmax(outputs[task], dim=1)
                        if task == 'gesture':
                            correct = (pred == gesture_labels).sum().item()
                        elif task == 'chinese':
                            correct = (pred == chinese_labels).sum().item()
                        else:
                            correct = (pred == english_labels).sum().item()

                        task_correct[task] += correct
                        task_losses[task] += losses[task].item()

                    correct_predictions += task_correct['gesture']

                else:
                    inputs, labels = batch
                    inputs = inputs.to(self.device)
                    labels = labels.to(self.device)

                    outputs = self.model(inputs)
                    total_batch_loss = self.criterion(outputs, labels)

                    pred = torch.argmax(outputs, dim=1)
                    correct_predictions += (pred == labels).sum().item()

                total_loss += total_batch_loss.item()
                total_samples += inputs.size(0)

        avg_loss = total_loss / len(self.val_loader)
        avg_acc = correct_predictions / total_samples

        metrics = {'val_loss': avg_loss, 'val_acc': avg_acc}

        if self.is_multitask:
            for task in ['gesture', 'chinese', 'english']:
                metrics[f'val_{task}_loss'] = task_losses[task] / len(self.val_loader)
                metrics[f'val_{task}_acc'] = task_correct[task] / total_samples

        return metrics

    def train(self, epochs: int = 100, verbose: bool = True):
        """è®­ç»ƒæ¨¡å‹"""
        print(f"å¼€å§‹è®­ç»ƒï¼Œå…±{epochs}ä¸ªepoch")
        print(f"æ¨¡å‹ä¿å­˜ç›®å½•: {os.path.abspath(self.save_dir)}")
        print("=" * 50)

        start_time = time.time()
        best_val_acc = 0.0
        best_train_acc = 0.0  # å¦‚æœæ²¡æœ‰éªŒè¯é›†ï¼Œä½¿ç”¨è®­ç»ƒå‡†ç¡®ç‡

        for epoch in range(epochs):
            epoch_start_time = time.time()

            # è®­ç»ƒ
            train_metrics = self.train_epoch()

            # éªŒè¯
            val_metrics = self.validate_epoch()

            # æ›´æ–°å­¦ä¹ ç‡
            if self.scheduler:
                if isinstance(self.scheduler, optim.lr_scheduler.ReduceLROnPlateau):
                    if val_metrics:
                        self.scheduler.step(val_metrics['val_loss'])
                    else:
                        self.scheduler.step(train_metrics['train_loss'])
                else:
                    self.scheduler.step()

            # è®°å½•æŒ‡æ ‡
            current_lr = self.optimizer.param_groups[0]['lr']
            all_metrics = {**train_metrics, **val_metrics, 'learning_rate': current_lr}
            self.metrics_tracker.update(all_metrics)

            # å†³å®šæ˜¯å¦ä¿å­˜æ¨¡å‹
            should_save = False
            current_acc = 0.0

            if val_metrics and 'val_acc' in val_metrics:
                current_acc = val_metrics['val_acc']
                if current_acc > best_val_acc:
                    best_val_acc = current_acc
                    should_save = True
            else:
                # æ²¡æœ‰éªŒè¯é›†æ—¶ä½¿ç”¨è®­ç»ƒå‡†ç¡®ç‡
                current_acc = train_metrics['train_acc']
                if current_acc > best_train_acc:
                    best_train_acc = current_acc
                    should_save = True

            # ä¿å­˜æ£€æŸ¥ç‚¹ï¼ˆæ¯10ä¸ªepochæˆ–æœ€ä½³æ¨¡å‹ï¼‰
            if should_save:
                self.save_checkpoint(epoch, is_best=True)
            elif epoch % 10 == 0 or epoch == epochs - 1:
                self.save_checkpoint(epoch, is_best=False)

            # æ—©åœæ£€æŸ¥
            if self.early_stopping and val_metrics:
                if self.early_stopping(val_metrics['val_loss'], self.model):
                    print(f"\næ—©åœè§¦å‘ï¼Œåœ¨ç¬¬{epoch + 1}ä¸ªepochåœæ­¢è®­ç»ƒ")
                    break

            # æ‰“å°è¿›åº¦
            if verbose:
                epoch_time = time.time() - epoch_start_time
                print(f"Epoch [{epoch + 1}/{epochs}] - {epoch_time:.2f}s")
                print(f"  è®­ç»ƒ: Loss={train_metrics['train_loss']:.4f}, Acc={train_metrics['train_acc']:.4f}")
                if val_metrics:
                    print(f"  éªŒè¯: Loss={val_metrics['val_loss']:.4f}, Acc={val_metrics['val_acc']:.4f}")
                print(f"  å­¦ä¹ ç‡: {current_lr:.6f}")
                if should_save:
                    print(f"  ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ (å‡†ç¡®ç‡: {current_acc:.4f})")

                # æ£€æŸ¥è®­ç»ƒè´¨é‡
                if epoch > 10:
                    if train_metrics['train_acc'] > 0.95 and (not val_metrics or val_metrics.get('val_acc', 0) < 0.7):
                        print(
                            f"  âš ï¸ å¯èƒ½è¿‡æ‹Ÿåˆï¼šè®­ç»ƒå‡†ç¡®ç‡{train_metrics['train_acc']:.3f}ï¼ŒéªŒè¯å‡†ç¡®ç‡{val_metrics.get('val_acc', 0):.3f}")
                    elif train_metrics['train_acc'] < 0.6 and epoch > 50:
                        print(f"  âš ï¸ è®­ç»ƒå›°éš¾ï¼šå‡†ç¡®ç‡ä»ç„¶å¾ˆä½ï¼Œè€ƒè™‘è°ƒæ•´å­¦ä¹ ç‡æˆ–æ•°æ®è´¨é‡")

                print("-" * 30)

        # è®­ç»ƒç»“æŸåä¿å­˜æœ€ç»ˆæ¨¡å‹
        final_save_path = os.path.join(self.save_dir, f"final_{self.model_type}_model.pth")
        try:
            torch.save({
                'model_state_dict': self.model.state_dict(),
                'model_type': self.model_type,
                'final_epoch': epochs,
                'best_acc': max(best_val_acc, best_train_acc),
                'timestamp': datetime.now().strftime("%Y%m%d_%H%M%S")
            }, final_save_path)
            print(f"âœ… æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜: {os.path.abspath(final_save_path)}")
        except Exception as e:
            print(f"âŒ æœ€ç»ˆæ¨¡å‹ä¿å­˜å¤±è´¥: {e}")

        total_time = time.time() - start_time
        final_best = max(best_val_acc, best_train_acc)
        print(f"\nğŸ‰ è®­ç»ƒå®Œæˆ!")
        print(f"   æ€»ç”¨æ—¶: {total_time:.2f}ç§’")
        print(f"   æœ€ä½³å‡†ç¡®ç‡: {final_best:.4f}")
        print(f"   æ¨¡å‹æ–‡ä»¶ä¿å­˜åœ¨: {os.path.abspath(self.save_dir)}")

        # åˆ—å‡ºä¿å­˜çš„æ–‡ä»¶
        try:
            saved_files = [f for f in os.listdir(self.save_dir) if f.endswith('.pth')]
            if saved_files:
                print(f"\nğŸ“ å·²ä¿å­˜çš„æ¨¡å‹æ–‡ä»¶:")
                for file in saved_files:
                    filepath = os.path.join(self.save_dir, file)
                    size = os.path.getsize(filepath) / (1024 * 1024)
                    print(f"   - {file} ({size:.2f} MB)")
            else:
                print(f"âš ï¸  è­¦å‘Š: æ¨¡å‹ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°ä¿å­˜çš„æ–‡ä»¶")
        except Exception as e:
            print(f"æ— æ³•åˆ—å‡ºä¿å­˜çš„æ–‡ä»¶: {e}")

    def evaluate(self, loader: DataLoader = None) -> Dict[str, Any]:
        """è¯„ä¼°æ¨¡å‹"""
        if loader is None:
            loader = self.test_loader

        self.model.eval()

        all_predictions = []
        all_labels = []
        total_loss = 0.0

        with torch.no_grad():
            for batch in tqdm(loader, desc="è¯„ä¼°ä¸­"):
                if self.is_multitask:
                    inputs, gesture_labels, chinese_labels, english_labels = batch
                    inputs = inputs.to(self.device)
                    gesture_labels = gesture_labels.to(self.device)

                    outputs = self.model(inputs)
                    pred = torch.argmax(outputs['gesture'], dim=1)

                    all_predictions.extend(pred.cpu().numpy())
                    all_labels.extend(gesture_labels.cpu().numpy())

                else:
                    inputs, labels = batch
                    inputs = inputs.to(self.device)
                    labels = labels.to(self.device)

                    outputs = self.model(inputs)
                    pred = torch.argmax(outputs, dim=1)

                    all_predictions.extend(pred.cpu().numpy())
                    all_labels.extend(labels.cpu().numpy())

                    loss = self.criterion(outputs, labels)
                    total_loss += loss.item()

        # è®¡ç®—æŒ‡æ ‡
        accuracy = accuracy_score(all_labels, all_predictions)

        # åˆ†ç±»æŠ¥å‘Š
        class_report = classification_report(all_labels, all_predictions, output_dict=True)

        # æ··æ·†çŸ©é˜µ
        cm = confusion_matrix(all_labels, all_predictions)

        results = {
            'accuracy': accuracy,
            'avg_loss': total_loss / len(loader),
            'classification_report': class_report,
            'confusion_matrix': cm,
            'predictions': all_predictions,
            'true_labels': all_labels
        }

        print(f"è¯„ä¼°ç»“æœ:")
        print(f"  å‡†ç¡®ç‡: {accuracy:.4f}")
        print(f"  å¹³å‡æŸå¤±: {results['avg_loss']:.4f}")

        return results

    def save_checkpoint(self, epoch: int, is_best: bool = False):
        """ä¿å­˜æ£€æŸ¥ç‚¹ - åŒ…å«å®Œæ•´æ¨¡å‹é…ç½®"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
        os.makedirs(self.save_dir, exist_ok=True)

        # æ„å»ºæ¨¡å‹é…ç½®
        model_config = {}

        if hasattr(self.model, '__dict__'):
            # å°è¯•æå–æ¨¡å‹å‚æ•°
            if self.model_type == "cnn_lstm":
                if hasattr(self.model, 'cnn_extractor') and hasattr(self.model.cnn_extractor, 'cnn_layers'):
                    # æå–CNNé€šé“é…ç½®
                    cnn_layers = self.model.cnn_extractor.cnn_layers
                    cnn_channels = []
                    for i, layer in enumerate(cnn_layers):
                        if isinstance(layer, nn.Conv1d):
                            cnn_channels.append(layer.out_channels)
                    model_config['cnn_channels'] = cnn_channels

                if hasattr(self.model, 'lstm'):
                    model_config['lstm_hidden_size'] = self.model.lstm.hidden_size
                    model_config['lstm_num_layers'] = self.model.lstm.num_layers
                    model_config['bidirectional'] = self.model.lstm.bidirectional

                if hasattr(self.model, 'classifier') and len(self.model.classifier) > 1:
                    if isinstance(self.model.classifier[1], nn.Linear):
                        model_config['classifier_hidden_size'] = self.model.classifier[1].out_features

            elif self.model_type == "lstm":
                if hasattr(self.model, 'lstm'):
                    model_config['hidden_dim'] = self.model.lstm.hidden_size
                    model_config['num_layers'] = self.model.lstm.num_layers
                    model_config['bidirectional'] = self.model.lstm.bidirectional

        checkpoint = {
            'epoch': epoch,
            'model_type': self.model_type,
            'model_state_dict': self.model.state_dict(),
            'model_config': model_config,  # é‡è¦ï¼šä¿å­˜æ¨¡å‹é…ç½®
            'optimizer_state_dict': self.optimizer.state_dict(),
            'metrics_history': self.metrics_tracker.history,
            'is_multitask': self.is_multitask,
            'input_dim': self.input_dim,
            'num_classes': self.num_classes,
            'timestamp': timestamp
        }

        if is_best:
            filename = f"best_{self.model_type}_model.pth"
        else:
            filename = f"{self.model_type}_checkpoint_epoch_{epoch + 1}.pth"

        filepath = os.path.join(self.save_dir, filename)

        try:
            torch.save(checkpoint, filepath)
            print(f"âœ… æ¨¡å‹å·²ä¿å­˜: {os.path.abspath(filepath)}")
            print(f"   ä¿å­˜çš„é…ç½®: {model_config}")

            # éªŒè¯æ–‡ä»¶æ˜¯å¦çœŸçš„å­˜åœ¨
            if os.path.exists(filepath):
                file_size = os.path.getsize(filepath) / (1024 * 1024)  # MB
                print(f"   æ–‡ä»¶å¤§å°: {file_size:.2f} MB")

        except Exception as e:
            print(f"âŒ æ¨¡å‹ä¿å­˜å¤±è´¥: {e}")

            # å°è¯•åœ¨å½“å‰ç›®å½•ä¿å­˜
            try:
                fallback_path = f"backup_{filename}"
                torch.save(checkpoint, fallback_path)
                print(f"âœ… å¤‡ç”¨ä¿å­˜æˆåŠŸ: {os.path.abspath(fallback_path)}")
            except Exception as e2:
                print(f"âŒ å¤‡ç”¨ä¿å­˜ä¹Ÿå¤±è´¥: {e2}")

    # ==================== ä¿®å¤5: å¿«é€Ÿä¿®å¤è„šæœ¬ ====================

    def quick_fix_model_loading():
        """å¿«é€Ÿä¿®å¤ç°æœ‰æ¨¡å‹çš„åŠ è½½é—®é¢˜"""
        print("ğŸ”§ å¿«é€Ÿä¿®å¤æ¨¡å‹åŠ è½½é—®é¢˜")
        print("=" * 40)

        models_dir = "data/models"
        if not os.path.exists(models_dir):
            print("âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨")
            return

        model_files = [f for f in os.listdir(models_dir) if f.endswith('.pth')]
        if not model_files:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶")
            return

        for model_file in model_files:
            model_path = os.path.join(models_dir, model_file)
            print(f"\næ£€æŸ¥æ¨¡å‹: {model_file}")

            try:
                # åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹
                checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)

                # åˆ†ææ¨¡å‹æ¶æ„
                state_dict = checkpoint['model_state_dict']

                # æ¨æ–­é…ç½®
                config = {}

                if 'cnn_extractor.cnn_layers.0.weight' in state_dict:
                    first_cnn = state_dict['cnn_extractor.cnn_layers.0.weight'].shape[0]
                    config['cnn_channels'] = [first_cnn]

                    if 'cnn_extractor.cnn_layers.5.weight' in state_dict:
                        second_cnn = state_dict['cnn_extractor.cnn_layers.5.weight'].shape[0]
                        config['cnn_channels'].append(second_cnn)

                if 'lstm.weight_ih_l0' in state_dict:
                    lstm_hidden = state_dict['lstm.weight_ih_l0'].shape[0] // 4
                    config['lstm_hidden_size'] = lstm_hidden
                    config['lstm_num_layers'] = 2 if 'lstm.weight_ih_l1' in state_dict else 1
                    config['bidirectional'] = 'lstm.weight_ih_l0_reverse' in state_dict

                if 'classifier.1.weight' in state_dict:
                    classifier_hidden = state_dict['classifier.1.weight'].shape[0]
                    config['classifier_hidden_size'] = classifier_hidden

                print(f"æ¨æ–­é…ç½®: {config}")

                # æ›´æ–°æ¨¡å‹æ£€æŸ¥ç‚¹
                if config and 'model_config' not in checkpoint:
                    checkpoint['model_config'] = config

                    # ä¿å­˜ä¿®å¤åçš„æ¨¡å‹
                    fixed_path = model_path.replace('.pth', '_fixed.pth')
                    torch.save(checkpoint, fixed_path)
                    print(f"âœ… ä¿®å¤åæ¨¡å‹å·²ä¿å­˜: {fixed_path}")
                else:
                    print("âœ… æ¨¡å‹å·²åŒ…å«é…ç½®ä¿¡æ¯")

            except Exception as e:
                print(f"âŒ å¤„ç†å¤±è´¥: {e}")

    def load_checkpoint(self, filepath: str):
        """åŠ è½½æ£€æŸ¥ç‚¹"""
        checkpoint = torch.load(filepath, map_location=self.device)

        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        self.metrics_tracker.history = checkpoint['metrics_history']

        print(f"æ¨¡å‹æ£€æŸ¥ç‚¹å·²åŠ è½½: {filepath}")
        return checkpoint['epoch']

    def plot_training_history(self, save_path: str = None):
        """ç»˜åˆ¶è®­ç»ƒå†å²"""
        if save_path is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            save_path = os.path.join(self.save_dir, f"training_history_{self.model_type}_{timestamp}.png")

        # ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(save_path), exist_ok=True)

        try:
            self.metrics_tracker.plot_history(save_path)
        except Exception as e:
            print(f"âŒ è®­ç»ƒå†å²å›¾ä¿å­˜å¤±è´¥: {e}")
            # å°è¯•ä¿å­˜åˆ°å½“å‰ç›®å½•
            try:
                fallback_path = f"training_history_{self.model_type}.png"
                self.metrics_tracker.plot_history(fallback_path)
                print(f"âœ… è®­ç»ƒå†å²å›¾å¤‡ç”¨ä¿å­˜: {os.path.abspath(fallback_path)}")
            except Exception as e2:
                print(f"âŒ å¤‡ç”¨ä¿å­˜ä¹Ÿå¤±è´¥: {e2}")


def main():
    """ä¸»å‡½æ•° - å®Œæ•´çš„è®­ç»ƒæµç¨‹"""
    print("æ‰‹è¯­è¯†åˆ«æ¨¡å‹è®­ç»ƒå™¨")
    print("=" * 50)

    # 1. æ£€æŸ¥é¢„å¤„ç†æ•°æ®æ–‡ä»¶
    data_dir = "data/processed"
    if not os.path.exists(data_dir):
        print("âŒ æ‰¾ä¸åˆ°é¢„å¤„ç†æ•°æ®ç›®å½•")
        print("è¯·å…ˆè¿è¡Œ data_preprocessor.py ç”Ÿæˆé¢„å¤„ç†æ•°æ®")
        return

    # æŸ¥æ‰¾æœ€æ–°çš„é¢„å¤„ç†æ•°æ®æ–‡ä»¶
    processed_files = [f for f in os.listdir(data_dir) if f.startswith("processed_data_") and f.endswith(".pkl")]
    if not processed_files:
        print("âŒ æ‰¾ä¸åˆ°é¢„å¤„ç†æ•°æ®æ–‡ä»¶")
        print("è¯·å…ˆè¿è¡Œ data_preprocessor.py ç”Ÿæˆé¢„å¤„ç†æ•°æ®")
        return

    # ä½¿ç”¨æœ€æ–°çš„æ•°æ®æ–‡ä»¶
    latest_file = sorted(processed_files)[-1]
    data_path = os.path.join(data_dir, latest_file)
    print(f"âœ… æ‰¾åˆ°é¢„å¤„ç†æ•°æ®æ–‡ä»¶: {latest_file}")

    # 2. åŠ è½½é¢„å¤„ç†æ•°æ®
    try:
        from data_preprocessor import HandGesturePreprocessor
        preprocessor = HandGesturePreprocessor()
        data_splits = preprocessor.load_processed_data(data_path)
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ")

        # æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡
        print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"   è®­ç»ƒé›†: {data_splits['X_train'].shape[0]} æ ·æœ¬")
        if 'X_val' in data_splits:
            print(f"   éªŒè¯é›†: {data_splits['X_val'].shape[0]} æ ·æœ¬")
        print(f"   æµ‹è¯•é›†: {data_splits['X_test'].shape[0]} æ ·æœ¬")
        print(f"   ç‰¹å¾ç»´åº¦: {data_splits['X_train'].shape[1]} Ã— {data_splits['X_train'].shape[2]}")

    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return

    # 3. é€‰æ‹©æ¨¡å‹ç±»å‹
    available_models = ["lstm", "gru", "transformer", "cnn_lstm", "attention_lstm", "resnet1d"]
    print(f"\nğŸ¤– å¯ç”¨çš„æ¨¡å‹ç±»å‹:")
    for i, model in enumerate(available_models, 1):
        print(f"   {i}. {model}")

    # è¿™é‡Œå¯ä»¥è‡ªåŠ¨é€‰æ‹©æˆ–è®©ç”¨æˆ·é€‰æ‹©
    model_type = "lstm"  # é»˜è®¤ä½¿ç”¨LSTMï¼Œä½ å¯ä»¥ä¿®æ”¹è¿™é‡Œ
    print(f"ğŸ¯ é€‰æ‹©æ¨¡å‹ç±»å‹: {model_type}")

    # 4. åˆ›å»ºè®­ç»ƒå™¨
    trainer = HandGestureTrainer(model_type=model_type)

    # 5. å‡†å¤‡æ•°æ®
    print(f"\nğŸ“¦ å‡†å¤‡æ•°æ®...")
    trainer.prepare_data(data_splits, batch_size=16, shuffle=True)

    # 6. æ„å»ºæ¨¡å‹
    print(f"\nğŸ—ï¸  æ„å»ºæ¨¡å‹...")
    if model_type == "lstm":
        trainer.build_model(
            hidden_dim=256,  # å¢åŠ æ¨¡å‹å®¹é‡
            num_layers=3,  # å¢åŠ å±‚æ•°
            dropout=0.5,  # å¢åŠ dropouté˜²æ­¢è¿‡æ‹Ÿåˆ
            bidirectional=True
        )
    elif model_type == "transformer":
        trainer.build_model(
            d_model=512,
            nhead=8,
            num_layers=6,
            dropout=0.2
        )
    elif model_type == "cnn_lstm":
        trainer.build_model(
            cnn_hidden_dims=[256, 512],
            lstm_hidden_dim=256,
            lstm_layers=3,
            dropout=0.5
        )
    else:
        trainer.build_model()  # ä½¿ç”¨é»˜è®¤å‚æ•°

    # 7. è®¾ç½®è®­ç»ƒå‚æ•°
    print(f"\nâš™ï¸  è®¾ç½®è®­ç»ƒå‚æ•°...")
    trainer.setup_training(
        learning_rate=0.01,  # æé«˜å­¦ä¹ ç‡
        optimizer_type="adam",
        scheduler_type="step",  # ä½¿ç”¨é˜¶æ¢¯å¼å­¦ä¹ ç‡
        weight_decay=1e-3,  # å¢åŠ æ­£åˆ™åŒ–
        use_early_stopping=True,
        patience=25  # å¢åŠ è€å¿ƒå€¼
    )

    # 8. å¼€å§‹è®­ç»ƒ
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ...")
    epochs = 200  # å¤§å¹…å¢åŠ è®­ç»ƒè½®æ•°
    trainer.train(epochs=epochs, verbose=True)

    # 9. è¯„ä¼°æ¨¡å‹
    print(f"\nğŸ“Š è¯„ä¼°æ¨¡å‹...")
    test_results = trainer.evaluate()

    print(f"\nâœ… è®­ç»ƒå®Œæˆ!")
    print(f"ğŸ“ˆ æœ€ç»ˆæµ‹è¯•ç»“æœ:")
    print(f"   å‡†ç¡®ç‡: {test_results['accuracy']:.4f}")
    print(f"   å¹³å‡æŸå¤±: {test_results['avg_loss']:.4f}")

    # 10. ç»˜åˆ¶è®­ç»ƒå†å²
    print(f"\nğŸ“Š ç”Ÿæˆè®­ç»ƒå†å²å›¾...")
    trainer.plot_training_history()

    # 11. ä¿å­˜æœ€ç»ˆç»Ÿè®¡
    stats = {
        'model_type': model_type,
        'epochs': epochs,
        'final_accuracy': test_results['accuracy'],
        'final_loss': test_results['avg_loss'],
        'train_samples': len(data_splits['X_train']),
        'test_samples': len(data_splits['X_test']),
        'timestamp': datetime.now().isoformat()
    }

    # ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
    os.makedirs(trainer.save_dir, exist_ok=True)
    stats_file = os.path.join(trainer.save_dir, f"training_stats_{model_type}.json")

    try:
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(stats, f, ensure_ascii=False, indent=2)
        print(f"âœ… è®­ç»ƒç»Ÿè®¡å·²ä¿å­˜: {os.path.abspath(stats_file)}")
    except Exception as e:
        print(f"âŒ ç»Ÿè®¡ä¿å­˜å¤±è´¥: {e}")
        # å°è¯•ä¿å­˜åˆ°å½“å‰ç›®å½•
        try:
            fallback_stats = f"training_stats_{model_type}.json"
            with open(fallback_stats, 'w', encoding='utf-8') as f:
                json.dump(stats, f, ensure_ascii=False, indent=2)
            print(f"âœ… ç»Ÿè®¡å¤‡ç”¨ä¿å­˜: {os.path.abspath(fallback_stats)}")
        except Exception as e2:
            print(f"âŒ å¤‡ç”¨ç»Ÿè®¡ä¿å­˜å¤±è´¥: {e2}")

    print(f"\nğŸ‰ æ¨¡å‹è®­ç»ƒæµç¨‹å…¨éƒ¨å®Œæˆ!")
    print(f"ğŸ“ è®­ç»ƒç»“æœä¿å­˜ç›®å½•: {os.path.abspath(trainer.save_dir)}")

    # åˆ—å‡ºæ‰€æœ‰ä¿å­˜çš„æ–‡ä»¶
    try:
        print(f"\nğŸ“‹ ç”Ÿæˆçš„æ–‡ä»¶åˆ—è¡¨:")
        all_files = []

        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
        if os.path.exists(trainer.save_dir):
            model_files = [f for f in os.listdir(trainer.save_dir) if f.endswith(('.pth', '.png', '.json'))]
            for file in model_files:
                filepath = os.path.join(trainer.save_dir, file)
                size = os.path.getsize(filepath) / (1024 * 1024)
                print(f"   ğŸ“„ {file} ({size:.2f} MB)")
                all_files.append(file)

        # æ£€æŸ¥å½“å‰ç›®å½•çš„å¤‡ç”¨æ–‡ä»¶
        current_files = [f for f in os.listdir('.') if
                         f.startswith(('backup_', 'training_', 'final_')) and f.endswith(('.pth', '.png', '.json'))]
        for file in current_files:
            if file not in all_files:
                size = os.path.getsize(file) / (1024 * 1024)
                print(f"   ğŸ“„ {file} ({size:.2f} MB) [å½“å‰ç›®å½•]")

        if not all_files and not current_files:
            print("   âš ï¸  æ²¡æœ‰æ‰¾åˆ°ä¿å­˜çš„æ–‡ä»¶")

    except Exception as e:
        print(f"æ— æ³•åˆ—å‡ºæ–‡ä»¶: {e}")


def train_multiple_models():
    """è®­ç»ƒå¤šä¸ªæ¨¡å‹è¿›è¡Œå¯¹æ¯”"""
    print("å¤šæ¨¡å‹å¯¹æ¯”è®­ç»ƒ")
    print("=" * 50)

    # åŠ è½½æ•°æ®
    data_dir = "data/processed"
    processed_files = [f for f in os.listdir(data_dir) if f.startswith("processed_data_") and f.endswith(".pkl")]
    if not processed_files:
        print("âŒ æ‰¾ä¸åˆ°é¢„å¤„ç†æ•°æ®æ–‡ä»¶")
        return

    latest_file = sorted(processed_files)[-1]
    data_path = os.path.join(data_dir, latest_file)

    from data_preprocessor import HandGesturePreprocessor
    preprocessor = HandGesturePreprocessor()
    data_splits = preprocessor.load_processed_data(data_path)

    # è¦è®­ç»ƒçš„æ¨¡å‹åˆ—è¡¨
    models_to_train = ["lstm", "gru", "cnn_lstm"]
    results = {}

    for model_type in models_to_train:
        print(f"\n{'=' * 20} è®­ç»ƒ {model_type.upper()} æ¨¡å‹ {'=' * 20}")

        try:
            # åˆ›å»ºè®­ç»ƒå™¨
            trainer = HandGestureTrainer(model_type=model_type)
            trainer.prepare_data(data_splits, batch_size=16)
            trainer.build_model()
            trainer.setup_training(learning_rate=0.001, use_early_stopping=True, patience=10)

            # è®­ç»ƒ
            trainer.train(epochs=30, verbose=False)

            # è¯„ä¼°
            test_results = trainer.evaluate()
            results[model_type] = {
                'accuracy': test_results['accuracy'],
                'loss': test_results['avg_loss']
            }

            print(f"âœ… {model_type} å®Œæˆ - å‡†ç¡®ç‡: {test_results['accuracy']:.4f}")

        except Exception as e:
            print(f"âŒ {model_type} è®­ç»ƒå¤±è´¥: {e}")
            results[model_type] = {'accuracy': 0.0, 'loss': float('inf')}

    # æ˜¾ç¤ºå¯¹æ¯”ç»“æœ
    print(f"\nğŸ“Š æ¨¡å‹å¯¹æ¯”ç»“æœ:")
    print("-" * 60)
    print(f"{'æ¨¡å‹ç±»å‹':<15} {'å‡†ç¡®ç‡':<10} {'æŸå¤±':<10}")
    print("-" * 60)

    best_model = max(results.keys(), key=lambda x: results[x]['accuracy'])

    for model_type, metrics in results.items():
        marker = " ğŸ†" if model_type == best_model else ""
        print(f"{model_type:<15} {metrics['accuracy']:<10.4f} {metrics['loss']:<10.4f}{marker}")

    print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model} (å‡†ç¡®ç‡: {results[best_model]['accuracy']:.4f})")


def quick_train():
    """å¿«é€Ÿè®­ç»ƒï¼ˆä½¿ç”¨é»˜è®¤å‚æ•°ï¼‰"""
    print("å¿«é€Ÿè®­ç»ƒæ¨¡å¼")
    print("=" * 30)

    try:
        # æŸ¥æ‰¾æ•°æ®
        data_dir = "data/processed"
        processed_files = [f for f in os.listdir(data_dir) if f.startswith("processed_data_") and f.endswith(".pkl")]
        latest_file = sorted(processed_files)[-1]
        data_path = os.path.join(data_dir, latest_file)

        # åŠ è½½æ•°æ®
        from data_preprocessor import HandGesturePreprocessor
        preprocessor = HandGesturePreprocessor()
        data_splits = preprocessor.load_processed_data(data_path)

        # å¿«é€Ÿè®­ç»ƒ
        trainer = HandGestureTrainer(model_type="lstm")
        trainer.prepare_data(data_splits, batch_size=32)
        trainer.build_model(hidden_dim=64, num_layers=1)  # ç®€åŒ–æ¨¡å‹
        trainer.setup_training(learning_rate=0.01, use_early_stopping=True, patience=5)
        trainer.train(epochs=20, verbose=True)

        # è¯„ä¼°
        results = trainer.evaluate()
        print(f"\nâœ… å¿«é€Ÿè®­ç»ƒå®Œæˆ!")
        print(f"å‡†ç¡®ç‡: {results['accuracy']:.4f}")

    except Exception as e:
        print(f"âŒ å¿«é€Ÿè®­ç»ƒå¤±è´¥: {e}")


if __name__ == "__main__":
    import sys

    if len(sys.argv) > 1:
        if sys.argv[1] == "multi":
            train_multiple_models()
        elif sys.argv[1] == "quick":
            quick_train()
        else:
            print("ç”¨æ³•:")
            print("  python trainer.py        # å®Œæ•´è®­ç»ƒ")
            print("  python trainer.py multi  # å¤šæ¨¡å‹å¯¹æ¯”")
            print("  python trainer.py quick  # å¿«é€Ÿè®­ç»ƒ")
    else:
        main()